{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wikipedia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-2.1561e-02,  3.4155e-01,  2.0312e-01,  ..., -1.8567e-01,\n",
      "           1.7285e-01,  1.7609e-02],\n",
      "         [ 1.6138e-01,  5.6915e-02,  2.1277e-01,  ..., -4.0356e-01,\n",
      "           9.9304e-02,  1.4961e-04],\n",
      "         [ 2.9922e-02,  1.9971e-01,  1.5552e-01,  ..., -3.2532e-02,\n",
      "          -2.7490e-01,  2.5439e-01],\n",
      "         ...,\n",
      "         [ 2.2131e-01, -1.6388e-02,  9.1309e-02,  ..., -3.2715e-01,\n",
      "           4.0253e-02,  1.2610e-01],\n",
      "         [-1.2219e-01,  4.9744e-02,  5.0049e-01,  ..., -1.3269e-01,\n",
      "           7.0923e-02,  1.5308e-01],\n",
      "         [-2.5586e-01, -1.2891e-01,  1.8494e-01,  ..., -1.7651e-01,\n",
      "          -3.0231e-03,  1.4355e-01]],\n",
      "\n",
      "        [[-1.7548e-02,  3.1543e-01,  2.2375e-01,  ..., -2.1545e-01,\n",
      "           1.5479e-01,  1.8204e-02],\n",
      "         [-7.4646e-02,  1.5649e-01,  1.9312e-01,  ...,  4.6704e-01,\n",
      "           1.3660e-01,  2.8662e-01],\n",
      "         [-8.2581e-02, -2.9785e-02,  2.2141e-02,  ..., -1.6248e-01,\n",
      "          -1.3684e-01,  3.5522e-01],\n",
      "         ...,\n",
      "         [ 1.7261e-01,  3.6548e-01,  3.2739e-01,  ..., -5.9082e-02,\n",
      "          -1.4429e-01, -5.8105e-01],\n",
      "         [-2.6685e-01,  2.4390e-01,  1.7407e-01,  ...,  9.6558e-02,\n",
      "           1.5381e-01, -1.5088e-01],\n",
      "         [-4.9609e-01,  1.2042e-01,  1.0876e-01,  ...,  7.2449e-02,\n",
      "           1.2085e-02,  9.6619e-02]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[ 3947,   527,  1101,  1403, 53524, 14298, 18143,   304, 14972,   382,\n",
      "         26208,  2630,   374,   264,  3363,   304,  3400,    71,  1656,  6406,\n",
      "           304,   279,   549,   815,    13,  1614,   315, 14972,    13,  1102,\n",
      "           374,   459, 98812,   315,   279,  3363,   315, 16506, 24076,    13,\n",
      "           578,  7187,   574,   220,    20,    11, 16443,   520,   279,   220,\n",
      "          2366,    15, 44702,   382,    47,  7341,   271,    33, 29468,  5657,\n",
      "           198, 26208,  2630,   596,   426, 29468,  5657,   374,  7559,   520,\n",
      "           220, 17735, 28058, 17569,  1120,  1022,   386,    12,  4161,   323,\n",
      "           374, 53524,   596,  7928,  6246,   520,   662,  1102,   374,  2162,\n",
      "           311,   264,  6721,   220,   972, 87693, 13668, 19665,  3388,   323,\n",
      "         21685,   279,   220,  1049,    23, 11997, 28131,  4435, 19134,    13,\n",
      "           220,   763,  5369,   311,   279,  2624, 19665,  3388,    11,   426,\n",
      "         29468,  5657,  1101,   706,   279, 53524, 63422],\n",
      "        [17691,  1303,   279,  9578,    11,   477,   274, 24060,   449, 12290,\n",
      "            11,   374,   279, 28278,   315, 31135, 12290,   389,   279,  6732,\n",
      "           315,  9919, 24788,   291,   555, 51630,  1105,    13,  1102, 44853,\n",
      "           439,   264, 41100,   389,   312,  3502, 10796,  7709,   304,   279,\n",
      "         14154, 31494,  6460,   323,  6244,   264,  1664, 64868, 29036,  9761,\n",
      "           292, 60612,   304,   279, 12877, 50093,    13,   578,  1888, 22015,\n",
      "          3187,   374,   279,  4371,  1303,   315,  3005,  2464,   439, 13713,\n",
      "           660,   304,   279, 68201,  6017,   315, 86955,    11,   220,    24,\n",
      "            25,  1774,    13,   578, 10171,  4371,  1303,   315,  3341,   339,\n",
      "           425,   374,  1457, 11846,   311,   387,   264,   220,   777,   339,\n",
      "          9478, 28229,   382, 77713,   198,   791,  2587,   315,  4087,  7922,\n",
      "           477, 20503, 22696,   264, 14763,  3363,   449, 12290,   323, 24018,\n",
      "           287,  5606,   889, 76035,   311, 32593,   433]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-2.1561e-02,  3.4155e-01,  2.0312e-01,  ..., -1.8567e-01,\n",
      "          1.7285e-01,  1.7609e-02],\n",
      "        [ 1.6138e-01,  5.6915e-02,  2.1277e-01,  ..., -4.0356e-01,\n",
      "          9.9304e-02,  1.4961e-04],\n",
      "        [ 2.9922e-02,  1.9971e-01,  1.5552e-01,  ..., -3.2532e-02,\n",
      "         -2.7490e-01,  2.5439e-01],\n",
      "        ...,\n",
      "        [ 1.7261e-01,  3.6548e-01,  3.2739e-01,  ..., -5.9082e-02,\n",
      "         -1.4429e-01, -5.8105e-01],\n",
      "        [-2.6685e-01,  2.4390e-01,  1.7407e-01,  ...,  9.6558e-02,\n",
      "          1.5381e-01, -1.5088e-01],\n",
      "        [-4.9609e-01,  1.2042e-01,  1.0876e-01,  ...,  7.2449e-02,\n",
      "          1.2085e-02,  9.6619e-02]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([ 3947,   527,  1101,  1403, 53524, 14298, 18143,   304, 14972,   382,\n",
      "        26208,  2630,   374,   264,  3363,   304,  3400,    71,  1656,  6406,\n",
      "          304,   279,   549,   815,    13,  1614,   315, 14972,    13,  1102,\n",
      "          374,   459, 98812,   315,   279,  3363,   315, 16506, 24076,    13,\n",
      "          578,  7187,   574,   220,    20,    11, 16443,   520,   279,   220,\n",
      "         2366,    15, 44702,   382,    47,  7341,   271,    33, 29468,  5657,\n",
      "          198, 26208,  2630,   596,   426, 29468,  5657,   374,  7559,   520,\n",
      "          220, 17735, 28058, 17569,  1120,  1022,   386,    12,  4161,   323,\n",
      "          374, 53524,   596,  7928,  6246,   520,   662,  1102,   374,  2162,\n",
      "          311,   264,  6721,   220,   972, 87693, 13668, 19665,  3388,   323,\n",
      "        21685,   279,   220,  1049,    23, 11997, 28131,  4435, 19134,    13,\n",
      "          220,   763,  5369,   311,   279,  2624, 19665,  3388,    11,   426,\n",
      "        29468,  5657,  1101,   706,   279, 53524, 63422, 17691,  1303,   279,\n",
      "         9578,    11,   477,   274, 24060,   449, 12290,    11,   374,   279,\n",
      "        28278,   315, 31135, 12290,   389,   279,  6732,   315,  9919, 24788,\n",
      "          291,   555, 51630,  1105,    13,  1102, 44853,   439,   264, 41100,\n",
      "          389,   312,  3502, 10796,  7709,   304,   279, 14154, 31494,  6460,\n",
      "          323,  6244,   264,  1664, 64868, 29036,  9761,   292, 60612,   304,\n",
      "          279, 12877, 50093,    13,   578,  1888, 22015,  3187,   374,   279,\n",
      "         4371,  1303,   315,  3005,  2464,   439, 13713,   660,   304,   279,\n",
      "        68201,  6017,   315, 86955,    11,   220,    24,    25,  1774,    13,\n",
      "          578, 10171,  4371,  1303,   315,  3341,   339,   425,   374,  1457,\n",
      "        11846,   311,   387,   264,   220,   777,   339,  9478, 28229,   382,\n",
      "        77713,   198,   791,  2587,   315,  4087,  7922,   477, 20503, 22696,\n",
      "          264, 14763,  3363,   449, 12290,   323, 24018,   287,  5606,   889,\n",
      "        76035,   311, 32593,   433], device='cuda:0')\n",
      "Epoch 0, Batch 0, Loss: 11.530973434448242\n",
      "Batch 1, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-0.0141,  0.3367,  0.2350,  ..., -0.1932,  0.1469,  0.0269],\n",
      "         [ 0.3743, -0.1240,  0.3613,  ...,  0.3318, -0.2205,  0.5068],\n",
      "         [ 0.1888,  0.0874,  0.2524,  ...,  0.3848, -0.1185, -0.1270],\n",
      "         ...,\n",
      "         [ 0.0652,  0.3992,  0.1831,  ..., -0.7275,  0.1179, -0.1385],\n",
      "         [-0.0346, -0.1832, -0.0714,  ...,  0.1196, -0.1729,  0.1738],\n",
      "         [-0.3516, -0.0691, -0.0646,  ..., -0.3118, -0.2847,  0.3547]],\n",
      "\n",
      "        [[ 0.0150,  0.3247,  0.2365,  ..., -0.1899,  0.1847,  0.0299],\n",
      "         [ 0.1528,  0.1805, -0.1377,  ...,  0.0348, -0.0786, -0.0215],\n",
      "         [-0.3311,  0.0163,  0.1769,  ..., -0.1505,  0.0338,  0.1226],\n",
      "         ...,\n",
      "         [ 0.0876,  0.0466,  0.1871,  ...,  0.2678,  0.1382,  0.1083],\n",
      "         [-0.1630,  0.0665,  0.5581,  ..., -0.1660,  0.1121,  0.1212],\n",
      "         [ 0.0282, -0.2871,  0.1567,  ...,  0.3438, -0.0688,  0.5210]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[   42,   607,  4381, 16222,  6863,   374,   459,   653,  2910, 39382,\n",
      "           660,  4029,   323, 44702, 47117,   660,  2035,   320,  6620,    47,\n",
      "             8,   304, 28621,  6406,    11, 28621,    11,  3723,  4273,    13,\n",
      "          1102,   753,  1455, 17037, 14183,   311,  5042,   439,   735,  6863,\n",
      "           320,    64,   836,   433, 13551,   449,   279,  9474,   311,   902,\n",
      "           433, 17623,   705,   719,  1101,   439,   735,  6863, 14298,    11,\n",
      "           323, 23781,   439,   735,   607,  4381,   320,    64,   836,   433,\n",
      "         13551,   449,   264,  4029,   389,   279, 10160,  1637,  3185,   315,\n",
      "           507, 27793,   705,  8617,  1202,  2753, 21420,  1005,    13,   735,\n",
      "           607,  4381, 16222,  6863,   374,   279,  2132, 68067, 17516,   389,\n",
      "           279, 13218,   315, 28621,   320, 10924,   473, 18536,     8,   323,\n",
      "           279,  7928,   389,   279, 13218,   596,  9909,  3185,    11,  1405,\n",
      "           433,   374,   279,  4219,   315, 36754,   323],\n",
      "        [ 2520, 29393, 49774,    11,   264,  2410, 31412,  1963,  5643,   374,\n",
      "           459,  1963,   315,  2098, 16597,  5643, 32971,   555,  4815,  2940,\n",
      "           271,   438,   220,   374,   279, 47855, 19914,  3104,  1963,   439,\n",
      "           264,   734,   315,  6138,   505,   279, 24722,  8183,    11,   220,\n",
      "           374,   279, 47855, 19914,  3104,  1963,   389,  8183,    11,   220,\n",
      "           374,   279, 19914,  3104,  1963,   315,   279,  1206,  3071,    11,\n",
      "           902,   374,  4529,   311,   387, 87282, 39204,   220,   374,   279,\n",
      "          6332, 10801,    11,   323,   220,   374,   264,  5852,   430, 19170,\n",
      "           279,  6211,   315,   279,  5643,    13,   220,   374,  3629,  1511,\n",
      "           304,  2035,   315,   662, 32140,    11,   420,   374,  7170,  2663,\n",
      "           459,  8451,  5643,    13,  4815,  2520,   420,   538,   315, 21542,\n",
      "            11, 80149,   536, 50971,   374, 25655,   994,   220,  5097,   264,\n",
      "          4040,   907, 11911,   389,   279,  3769,  1511]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0141,  0.3367,  0.2350,  ..., -0.1932,  0.1469,  0.0269],\n",
      "        [ 0.3743, -0.1240,  0.3613,  ...,  0.3318, -0.2205,  0.5068],\n",
      "        [ 0.1888,  0.0874,  0.2524,  ...,  0.3848, -0.1185, -0.1270],\n",
      "        ...,\n",
      "        [ 0.0876,  0.0466,  0.1871,  ...,  0.2678,  0.1382,  0.1083],\n",
      "        [-0.1630,  0.0665,  0.5581,  ..., -0.1660,  0.1121,  0.1212],\n",
      "        [ 0.0282, -0.2871,  0.1567,  ...,  0.3438, -0.0688,  0.5210]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([   42,   607,  4381, 16222,  6863,   374,   459,   653,  2910, 39382,\n",
      "          660,  4029,   323, 44702, 47117,   660,  2035,   320,  6620,    47,\n",
      "            8,   304, 28621,  6406,    11, 28621,    11,  3723,  4273,    13,\n",
      "         1102,   753,  1455, 17037, 14183,   311,  5042,   439,   735,  6863,\n",
      "          320,    64,   836,   433, 13551,   449,   279,  9474,   311,   902,\n",
      "          433, 17623,   705,   719,  1101,   439,   735,  6863, 14298,    11,\n",
      "          323, 23781,   439,   735,   607,  4381,   320,    64,   836,   433,\n",
      "        13551,   449,   264,  4029,   389,   279, 10160,  1637,  3185,   315,\n",
      "          507, 27793,   705,  8617,  1202,  2753, 21420,  1005,    13,   735,\n",
      "          607,  4381, 16222,  6863,   374,   279,  2132, 68067, 17516,   389,\n",
      "          279, 13218,   315, 28621,   320, 10924,   473, 18536,     8,   323,\n",
      "          279,  7928,   389,   279, 13218,   596,  9909,  3185,    11,  1405,\n",
      "          433,   374,   279,  4219,   315, 36754,   323,  2520, 29393, 49774,\n",
      "           11,   264,  2410, 31412,  1963,  5643,   374,   459,  1963,   315,\n",
      "         2098, 16597,  5643, 32971,   555,  4815,  2940,   271,   438,   220,\n",
      "          374,   279, 47855, 19914,  3104,  1963,   439,   264,   734,   315,\n",
      "         6138,   505,   279, 24722,  8183,    11,   220,   374,   279, 47855,\n",
      "        19914,  3104,  1963,   389,  8183,    11,   220,   374,   279, 19914,\n",
      "         3104,  1963,   315,   279,  1206,  3071,    11,   902,   374,  4529,\n",
      "          311,   387, 87282, 39204,   220,   374,   279,  6332, 10801,    11,\n",
      "          323,   220,   374,   264,  5852,   430, 19170,   279,  6211,   315,\n",
      "          279,  5643,    13,   220,   374,  3629,  1511,   304,  2035,   315,\n",
      "          662, 32140,    11,   420,   374,  7170,  2663,   459,  8451,  5643,\n",
      "           13,  4815,  2520,   420,   538,   315, 21542,    11, 80149,   536,\n",
      "        50971,   374, 25655,   994,   220,  5097,   264,  4040,   907, 11911,\n",
      "          389,   279,  3769,  1511], device='cuda:0')\n",
      "Epoch 0, Batch 1, Loss: 11.553764343261719\n",
      "Batch 2, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[ 0.0347,  0.3276,  0.1882,  ..., -0.1953,  0.2020,  0.0419],\n",
      "         [-0.0758,  0.1561,  0.4204,  ...,  0.2159, -0.2203,  0.0909],\n",
      "         [ 0.2028,  0.2749,  0.0499,  ...,  0.0581,  0.1281, -0.2983],\n",
      "         ...,\n",
      "         [ 0.0819,  0.3154, -0.0356,  ...,  0.2377,  0.3777, -0.0441],\n",
      "         [-0.1063, -0.0518,  0.1809,  ...,  0.4602, -0.0168,  0.2698],\n",
      "         [-0.1738,  0.0187, -0.0813,  ...,  0.2107,  0.0256,  0.1218]],\n",
      "\n",
      "        [[ 0.0144,  0.3489,  0.1870,  ..., -0.2137,  0.1830,  0.0281],\n",
      "         [ 0.1886,  0.1984,  0.2922,  ...,  0.1461, -0.2693, -0.1210],\n",
      "         [-0.0464,  0.5283, -0.1605,  ...,  0.2318,  0.2305, -0.4019],\n",
      "         ...,\n",
      "         [ 0.1691, -0.4048,  0.4846,  ...,  0.1257, -0.1056,  0.1265],\n",
      "         [-0.3594,  0.1383,  0.1493,  ...,  0.1726,  0.0914,  0.0857],\n",
      "         [ 0.0573, -0.0459,  0.5684,  ...,  0.1019, -0.1232, -0.2246]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[   46,  2034,  1411,   374,   264, 14458,   304, 19001, 43089,  6406,\n",
      "            11, 25378,    11,  3723,  4273,    13,   578,  7187,   574,   220,\n",
      "          1187,   520,   279,   220,  2366,    15, 44702,   382, 13730,   198,\n",
      "            46,  2034,  1411,   574,   628, 12400,   304,   220,  9367,    21,\n",
      "            13,   323,  1455,  4461,  7086,  1306,   264, 51576,   893,    13,\n",
      "           362,  1772,  5274,  2663,   507,  2034,  1411,   574,  9749,   304,\n",
      "           220,  9367,    23,    11,   323, 14958,   304,  5784,  3156,   220,\n",
      "          5162,    20,   382,  9688,  5814,   198,    46,  2034,  1411,   374,\n",
      "          7559,   304, 19001, 43089,  6406,   389, 25378,  9767,   220, 10125,\n",
      "          1120,  9909,   315, 19152, 24076,    13, 39855,   374,   220,  1032,\n",
      "          8931,   311,   279, 11226,  3235, 25378,  9767, 30950,    13, 21750,\n",
      "           323, 72025,   265,  1065, 10457,   311,   279, 10411,   323, 10007,\n",
      "         15947,  3235,  9767,   220, 10125,    13,   578],\n",
      "        [   56, 10216,  6406, 31475,   468,   396,   359,    25, 44188,    12,\n",
      "          2032,   705, 19073,   279,  6406,   315,   816, 10216,    11,   374,\n",
      "           264, 14189,  7559,   304,   279, 18671, 13651,   315,   279,   549,\n",
      "           815,    13,  1614,   315,  7188,    13,   816, 10216,  6406,   574,\n",
      "           832,   315,   279,  4113, 31276,   315,  7188,    11,  3549,   304,\n",
      "           220,  9741,    15,   520,   279,   892,   315,  1614,  5812,    13,\n",
      "          1666,   315,   279,   220,  2366,    15, 44702,    11,   279,  7187,\n",
      "           574,   220, 12463,    11, 13074,    13, 11699, 14189, 10954,   374,\n",
      "         12404,  1974,   382,    56, 10216,  6406,   374,  5343,   304,   279,\n",
      "         33381, 41334, 58506,  3158,   323,   374,  7559,   304,   279, 41334,\n",
      "         13345,   382, 32960, 99174,   198,   644,   279,  4113,  1180,   315,\n",
      "           220,  9741,    15,   279,   836,   574, 68918,   330,    56,  8083,\n",
      "          1210,   816, 10216,   374,   264,  7281,  7678]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[ 0.0347,  0.3276,  0.1882,  ..., -0.1953,  0.2020,  0.0419],\n",
      "        [-0.0758,  0.1561,  0.4204,  ...,  0.2159, -0.2203,  0.0909],\n",
      "        [ 0.2028,  0.2749,  0.0499,  ...,  0.0581,  0.1281, -0.2983],\n",
      "        ...,\n",
      "        [ 0.1691, -0.4048,  0.4846,  ...,  0.1257, -0.1056,  0.1265],\n",
      "        [-0.3594,  0.1383,  0.1493,  ...,  0.1726,  0.0914,  0.0857],\n",
      "        [ 0.0573, -0.0459,  0.5684,  ...,  0.1019, -0.1232, -0.2246]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([   46,  2034,  1411,   374,   264, 14458,   304, 19001, 43089,  6406,\n",
      "           11, 25378,    11,  3723,  4273,    13,   578,  7187,   574,   220,\n",
      "         1187,   520,   279,   220,  2366,    15, 44702,   382, 13730,   198,\n",
      "           46,  2034,  1411,   574,   628, 12400,   304,   220,  9367,    21,\n",
      "           13,   323,  1455,  4461,  7086,  1306,   264, 51576,   893,    13,\n",
      "          362,  1772,  5274,  2663,   507,  2034,  1411,   574,  9749,   304,\n",
      "          220,  9367,    23,    11,   323, 14958,   304,  5784,  3156,   220,\n",
      "         5162,    20,   382,  9688,  5814,   198,    46,  2034,  1411,   374,\n",
      "         7559,   304, 19001, 43089,  6406,   389, 25378,  9767,   220, 10125,\n",
      "         1120,  9909,   315, 19152, 24076,    13, 39855,   374,   220,  1032,\n",
      "         8931,   311,   279, 11226,  3235, 25378,  9767, 30950,    13, 21750,\n",
      "          323, 72025,   265,  1065, 10457,   311,   279, 10411,   323, 10007,\n",
      "        15947,  3235,  9767,   220, 10125,    13,   578,    56, 10216,  6406,\n",
      "        31475,   468,   396,   359,    25, 44188,    12,  2032,   705, 19073,\n",
      "          279,  6406,   315,   816, 10216,    11,   374,   264, 14189,  7559,\n",
      "          304,   279, 18671, 13651,   315,   279,   549,   815,    13,  1614,\n",
      "          315,  7188,    13,   816, 10216,  6406,   574,   832,   315,   279,\n",
      "         4113, 31276,   315,  7188,    11,  3549,   304,   220,  9741,    15,\n",
      "          520,   279,   892,   315,  1614,  5812,    13,  1666,   315,   279,\n",
      "          220,  2366,    15, 44702,    11,   279,  7187,   574,   220, 12463,\n",
      "           11, 13074,    13, 11699, 14189, 10954,   374, 12404,  1974,   382,\n",
      "           56, 10216,  6406,   374,  5343,   304,   279, 33381, 41334, 58506,\n",
      "         3158,   323,   374,  7559,   304,   279, 41334, 13345,   382, 32960,\n",
      "        99174,   198,   644,   279,  4113,  1180,   315,   220,  9741,    15,\n",
      "          279,   836,   574, 68918,   330,    56,  8083,  1210,   816, 10216,\n",
      "          374,   264,  7281,  7678], device='cuda:0')\n",
      "Epoch 0, Batch 2, Loss: 11.53740119934082\n",
      "Batch 3, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[ 0.0063,  0.3467,  0.2045,  ..., -0.1824,  0.1857,  0.0041],\n",
      "         [-0.1863,  0.2220, -0.1550,  ..., -0.0517, -0.0404,  0.2094],\n",
      "         [-0.2634, -0.0632,  0.3340,  ..., -0.2910,  0.2805,  0.0297],\n",
      "         ...,\n",
      "         [ 0.0225,  0.0517, -0.0761,  ..., -0.2500,  0.4519,  0.4519],\n",
      "         [-0.1238,  0.0291,  0.5737,  ..., -0.1415,  0.1003,  0.1949],\n",
      "         [-0.0770, -0.0888,  0.0076,  ..., -0.2822,  0.3135, -0.1240]],\n",
      "\n",
      "        [[-0.0225,  0.3484,  0.2179,  ..., -0.1681,  0.2043,  0.0120],\n",
      "         [-0.0154,  0.0134,  0.0392,  ...,  0.1183,  0.1346, -0.4187],\n",
      "         [-0.0292,  0.2103,  0.7803,  ..., -0.2421, -0.4082, -0.0088],\n",
      "         ...,\n",
      "         [ 0.4690,  0.2139, -0.1270,  ...,  0.3594,  0.5049,  0.1032],\n",
      "         [ 0.1263, -0.2952,  0.4866,  ...,  0.2026, -0.1147,  0.0859],\n",
      "         [-0.0500, -0.1488, -0.1388,  ...,  0.2656, -0.2607,  0.1836]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[33103, 45245,   315, 38059,   374,   279,  2486,  5814,   315, 38059,\n",
      "            11, 11951, 18702,  7187, 17915,    11, 57978,    11,  6873,  2237,\n",
      "            11,  2890,   315,   279, 94920,    11,  7100,  2704,    11,   323,\n",
      "         10597, 12204,   811,    11,   439,  1664,   439,  1023, 13878,   315,\n",
      "           279, 79597,  7187,    13,   578, 79597,  7187, 54068,   304,   279,\n",
      "          3224,   315, 38059,    11,   264, 18455,  7559,   389,   279, 38785,\n",
      "         13962,   315,  4892, 10384,    11,   311,   279,  9909,   315,   323,\n",
      "         24894,   311, 15212,    13,   220,  5806,    88,   598,  3974,   304,\n",
      "         27852, 14559,    13,  1102,   374,   279,  6864,   315,   279,  3224,\n",
      "           323,  1176,   304,  3878,   315, 16036,  7187,    11,  3235,   449,\n",
      "         68868,    11, 38059,   596,  2132,  7928,  3363,   382, 13730,  4815,\n",
      "         50083,  2740,  9084,   655,    11,   927,   279, 24552,    11, 38059,\n",
      "           706,  1027, 25366,   555,   279,  2405, 16355],\n",
      "        [  791, 90232,   315,  4606,   477,  7665, 90232,    11,  1101,  3967,\n",
      "           439,   507,   451,   311, 28237,    11,   374,   264,  6710,   315,\n",
      "         42045,  4731, 30464,   505,   279,   864, 53638,   315,   279,  1620,\n",
      "          7351,   315,  2893, 93622,   596,   220,    24,   339, 63306, 24306,\n",
      "           304,   220, 10828,    18,    11, 13517,   743,   311,  4339, 30464,\n",
      "           505, 80474,  5124, 15610,   596,   220, 11256,    20, 33894,   330,\n",
      "            46,   451,   311, 28237,  3343,   763,   220,  4468,    17,    11,\n",
      "           279,  9251,   315,  4606, 18306,   433,   439,   459, 56664,   311,\n",
      "          4097,  4606,    11,   323,  3010,   304,   220,  3753,    20,   433,\n",
      "           574,  1101, 18306,   555,   279,  7665,  9323,   382, 37220,  7580,\n",
      "           374,   311, 34662,  6222,  7665,  2819,    13,   578, 10013, 16964,\n",
      "           433,   439, 37810,   279, 52805,   315, 11542,    11,  9096,   323,\n",
      "         44254,    13,   578, 56664,   374,  6476,   389]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[ 0.0063,  0.3467,  0.2045,  ..., -0.1824,  0.1857,  0.0041],\n",
      "        [-0.1863,  0.2220, -0.1550,  ..., -0.0517, -0.0404,  0.2094],\n",
      "        [-0.2634, -0.0632,  0.3340,  ..., -0.2910,  0.2805,  0.0297],\n",
      "        ...,\n",
      "        [ 0.4690,  0.2139, -0.1270,  ...,  0.3594,  0.5049,  0.1032],\n",
      "        [ 0.1263, -0.2952,  0.4866,  ...,  0.2026, -0.1147,  0.0859],\n",
      "        [-0.0500, -0.1488, -0.1388,  ...,  0.2656, -0.2607,  0.1836]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([33103, 45245,   315, 38059,   374,   279,  2486,  5814,   315, 38059,\n",
      "           11, 11951, 18702,  7187, 17915,    11, 57978,    11,  6873,  2237,\n",
      "           11,  2890,   315,   279, 94920,    11,  7100,  2704,    11,   323,\n",
      "        10597, 12204,   811,    11,   439,  1664,   439,  1023, 13878,   315,\n",
      "          279, 79597,  7187,    13,   578, 79597,  7187, 54068,   304,   279,\n",
      "         3224,   315, 38059,    11,   264, 18455,  7559,   389,   279, 38785,\n",
      "        13962,   315,  4892, 10384,    11,   311,   279,  9909,   315,   323,\n",
      "        24894,   311, 15212,    13,   220,  5806,    88,   598,  3974,   304,\n",
      "        27852, 14559,    13,  1102,   374,   279,  6864,   315,   279,  3224,\n",
      "          323,  1176,   304,  3878,   315, 16036,  7187,    11,  3235,   449,\n",
      "        68868,    11, 38059,   596,  2132,  7928,  3363,   382, 13730,  4815,\n",
      "        50083,  2740,  9084,   655,    11,   927,   279, 24552,    11, 38059,\n",
      "          706,  1027, 25366,   555,   279,  2405, 16355,   791, 90232,   315,\n",
      "         4606,   477,  7665, 90232,    11,  1101,  3967,   439,   507,   451,\n",
      "          311, 28237,    11,   374,   264,  6710,   315, 42045,  4731, 30464,\n",
      "          505,   279,   864, 53638,   315,   279,  1620,  7351,   315,  2893,\n",
      "        93622,   596,   220,    24,   339, 63306, 24306,   304,   220, 10828,\n",
      "           18,    11, 13517,   743,   311,  4339, 30464,   505, 80474,  5124,\n",
      "        15610,   596,   220, 11256,    20, 33894,   330,    46,   451,   311,\n",
      "        28237,  3343,   763,   220,  4468,    17,    11,   279,  9251,   315,\n",
      "         4606, 18306,   433,   439,   459, 56664,   311,  4097,  4606,    11,\n",
      "          323,  3010,   304,   220,  3753,    20,   433,   574,  1101, 18306,\n",
      "          555,   279,  7665,  9323,   382, 37220,  7580,   374,   311, 34662,\n",
      "         6222,  7665,  2819,    13,   578, 10013, 16964,   433,   439, 37810,\n",
      "          279, 52805,   315, 11542,    11,  9096,   323, 44254,    13,   578,\n",
      "        56664,   374,  6476,   389], device='cuda:0')\n",
      "Epoch 0, Batch 3, Loss: 11.554010391235352\n",
      "Batch 4, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[ 0.0033,  0.3386,  0.2422,  ..., -0.2185,  0.1643,  0.0305],\n",
      "         [-0.1083,  0.1324,  0.4209,  ...,  0.2078, -0.1876,  0.0575],\n",
      "         [-0.1632, -0.0359, -0.1075,  ...,  0.0096,  0.0912,  0.0579],\n",
      "         ...,\n",
      "         [-0.0704,  0.5879, -0.1219,  ...,  0.2350, -0.1194, -0.2620],\n",
      "         [-0.0797, -0.2479, -0.0676,  ...,  0.1086, -0.1364,  0.1522],\n",
      "         [-0.1709,  0.0959,  0.5840,  ..., -0.1372,  0.0908,  0.1316]],\n",
      "\n",
      "        [[ 0.0058,  0.3547,  0.1941,  ..., -0.1957,  0.1456,  0.0508],\n",
      "         [-0.2671,  0.0390, -0.1914,  ...,  0.1740,  0.2927, -0.1908],\n",
      "         [-0.4697,  0.0462, -0.0070,  ...,  0.0118, -0.2620, -0.0936],\n",
      "         ...,\n",
      "         [-0.1910,  0.0520, -0.1580,  ...,  0.0851,  0.0344,  0.0754],\n",
      "         [-0.1255, -0.1573, -0.1313,  ..., -0.0837, -0.0240,  0.6099],\n",
      "         [-0.0645,  0.2174,  0.1791,  ...,  0.1798,  0.0325,  0.4238]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[   46,   441,  4842,   677,  2176,   320,   883,   374,   264,  3363,\n",
      "           304,   323,   279, 14189, 10954,   315,   507,   441,  4842,   677,\n",
      "          2176,  6406,    11,  9784,    11,  3723,  4273,    13,  1666,   315,\n",
      "           279,   220,  2366,    15,  2326, 44702,    11,   279,  3363,   596,\n",
      "          7187,   574,   220,    20,    11, 12375,   382,   791, 11940,   507,\n",
      "           441,  4842,   677,  2176,  3158,   574, 35906, 20727,   304,   279,\n",
      "           220,  5926,    23,   507,   441,  4842,   677,  2176, 38201,    11,\n",
      "           279,  1176, 12715, 10260,   220,    20, 49784,   304,   279,  4892,\n",
      "         23179,    13,  1115,   574,   832,   315,   279, 99469, 90127,  3596,\n",
      "           311, 13471,   279,  2326,   382,    46,   441,  4842,   677,  2176,\n",
      "           374, 10434,   555,   279,   507,   441,  4842,   677,  2176,  6406,\n",
      "         21348,   382, 13730,   271,    46,   441,  4842,   677,  2176,   374,\n",
      "          3345,   311,   279,  2816,   315,   279, 16506],\n",
      "        [   47,   273, 15969, 44299,   374,   264,  3363,   304, 41929, 13813,\n",
      "         53767,    11, 34644,  6406,    11, 21357,    11,  3723,  4273,    13,\n",
      "          2468,   279,   892,   315,   279,   220,  2366,    15, 44702,    11,\n",
      "           279,  7187,   574,   220,  5833,   382,  9688,  5814,   198, 11439,\n",
      "           311,   279,  3723,  4273, 46627, 22555,    11,   279,  3363,   706,\n",
      "           264,  2860,  3158,   315,  1174,   682,  4363,   382, 33103, 45245,\n",
      "           271,   679,    15, 44702,   198,  2170,   315,   279, 44702,   315,\n",
      "           220,   679,    15,    11,  1070,  1051,   220,  6365,  1274,    11,\n",
      "           220,  3174, 29939,    11,   323,   220,  2148,  8689,  5496,   304,\n",
      "           279,  3363,    13,   578,  7187, 17915,   574,   662,  2684,  1051,\n",
      "           220,  2618, 11983,  8316,   520,   459,  5578, 17915,   315,   662,\n",
      "           578, 19739, 27649,   315,   279,  3363,   574,   220,  1041,    13,\n",
      "            15,     4,  5929,    13, 41985,   477, 44862]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[ 0.0033,  0.3386,  0.2422,  ..., -0.2185,  0.1643,  0.0305],\n",
      "        [-0.1083,  0.1324,  0.4209,  ...,  0.2078, -0.1876,  0.0575],\n",
      "        [-0.1632, -0.0359, -0.1075,  ...,  0.0096,  0.0912,  0.0579],\n",
      "        ...,\n",
      "        [-0.1910,  0.0520, -0.1580,  ...,  0.0851,  0.0344,  0.0754],\n",
      "        [-0.1255, -0.1573, -0.1313,  ..., -0.0837, -0.0240,  0.6099],\n",
      "        [-0.0645,  0.2174,  0.1791,  ...,  0.1798,  0.0325,  0.4238]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([   46,   441,  4842,   677,  2176,   320,   883,   374,   264,  3363,\n",
      "          304,   323,   279, 14189, 10954,   315,   507,   441,  4842,   677,\n",
      "         2176,  6406,    11,  9784,    11,  3723,  4273,    13,  1666,   315,\n",
      "          279,   220,  2366,    15,  2326, 44702,    11,   279,  3363,   596,\n",
      "         7187,   574,   220,    20,    11, 12375,   382,   791, 11940,   507,\n",
      "          441,  4842,   677,  2176,  3158,   574, 35906, 20727,   304,   279,\n",
      "          220,  5926,    23,   507,   441,  4842,   677,  2176, 38201,    11,\n",
      "          279,  1176, 12715, 10260,   220,    20, 49784,   304,   279,  4892,\n",
      "        23179,    13,  1115,   574,   832,   315,   279, 99469, 90127,  3596,\n",
      "          311, 13471,   279,  2326,   382,    46,   441,  4842,   677,  2176,\n",
      "          374, 10434,   555,   279,   507,   441,  4842,   677,  2176,  6406,\n",
      "        21348,   382, 13730,   271,    46,   441,  4842,   677,  2176,   374,\n",
      "         3345,   311,   279,  2816,   315,   279, 16506,    47,   273, 15969,\n",
      "        44299,   374,   264,  3363,   304, 41929, 13813, 53767,    11, 34644,\n",
      "         6406,    11, 21357,    11,  3723,  4273,    13,  2468,   279,   892,\n",
      "          315,   279,   220,  2366,    15, 44702,    11,   279,  7187,   574,\n",
      "          220,  5833,   382,  9688,  5814,   198, 11439,   311,   279,  3723,\n",
      "         4273, 46627, 22555,    11,   279,  3363,   706,   264,  2860,  3158,\n",
      "          315,  1174,   682,  4363,   382, 33103, 45245,   271,   679,    15,\n",
      "        44702,   198,  2170,   315,   279, 44702,   315,   220,   679,    15,\n",
      "           11,  1070,  1051,   220,  6365,  1274,    11,   220,  3174, 29939,\n",
      "           11,   323,   220,  2148,  8689,  5496,   304,   279,  3363,    13,\n",
      "          578,  7187, 17915,   574,   662,  2684,  1051,   220,  2618, 11983,\n",
      "         8316,   520,   459,  5578, 17915,   315,   662,   578, 19739, 27649,\n",
      "          315,   279,  3363,   574,   220,  1041,    13,    15,     4,  5929,\n",
      "           13, 41985,   477, 44862], device='cuda:0')\n",
      "Epoch 0, Batch 4, Loss: 11.550196647644043\n",
      "Batch 5, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[ 3.8574e-02,  3.2764e-01,  1.6858e-01,  ..., -1.9714e-01,\n",
      "           1.8481e-01,  1.0323e-02],\n",
      "         [-1.0078e-02,  3.2730e-03,  1.0510e-01,  ...,  1.1926e-01,\n",
      "           1.1237e-01, -4.7412e-01],\n",
      "         [ 1.1945e-01, -1.2384e-01,  2.4695e-01,  ...,  3.3716e-01,\n",
      "           1.9421e-01,  2.6440e-01],\n",
      "         ...,\n",
      "         [ 1.3293e-01,  5.1709e-01,  1.0010e-01,  ..., -7.3433e-04,\n",
      "           1.1420e-01,  2.8271e-01],\n",
      "         [-1.0913e-01, -6.5125e-02,  3.1471e-05,  ...,  3.1226e-01,\n",
      "          -9.8633e-02,  2.7124e-01],\n",
      "         [-3.5400e-01,  1.0022e-01, -7.3792e-02,  ..., -7.3303e-02,\n",
      "           8.6609e-02, -6.3965e-02]],\n",
      "\n",
      "        [[-1.3168e-02,  3.2520e-01,  2.0435e-01,  ..., -2.0471e-01,\n",
      "           2.0532e-01,  3.9673e-02],\n",
      "         [ 1.7969e-01,  3.5132e-01,  3.6963e-01,  ..., -2.7148e-01,\n",
      "          -2.4756e-01, -1.8481e-01],\n",
      "         [ 1.4856e-01, -3.2739e-01,  5.1221e-01,  ...,  1.3245e-01,\n",
      "          -1.3269e-01,  1.5723e-01],\n",
      "         ...,\n",
      "         [ 1.2988e-01,  1.1298e-01,  5.9692e-02,  ..., -9.7046e-02,\n",
      "           3.0908e-01, -2.4329e-01],\n",
      "         [ 1.2720e-01, -1.7908e-01, -6.6772e-02,  ...,  5.8472e-02,\n",
      "          -1.1926e-01,  4.3213e-01],\n",
      "         [-2.0605e-01, -2.9816e-02, -1.5405e-01,  ...,  1.3184e-01,\n",
      "           6.5552e-02,  1.3672e-01]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[  791,  1274,   315, 57784,   527, 44029, 18255,  1139,  1403,  1925,\n",
      "         22277, 10977,    11, 18341,   356,  1100,   462,  2469,   323, 24666,\n",
      "           356,  1100,   462,  2469,    11,   889,  4430,  1690, 13042, 25022,\n",
      "           719, 10519, 12742, 40521,  3196,   389, 57978,    11, 13901,    11,\n",
      "          4221,    11,   323,  3345, 20405,   449, 25431,   323, 17442, 15947,\n",
      "            13, 13538,   279, 26086,  3940,   304,   220,  5162,    19,   279,\n",
      "         32538,   315, 57784,   320,  3473,   220,  2813,    13,    16,     4,\n",
      "         18341, 12365,   356,  1100,   462,  2469,    11,   220,   972,    13,\n",
      "            17,     4, 24666, 12365,   356,  1100,   462,  2469,    11,   366,\n",
      "            20,     4,  1023, 10977,    11, 15871, 39478,  5493,    11,   220,\n",
      "          2947,   263,  3695,    11,   323,  1023, 69345,     8,  1051, 77810,\n",
      "           927,   279,  4553, 13218,   382,   791, 24666, 30215,   315, 57784,\n",
      "           304,   220,  4468,    19,   409, 61596, 17071],\n",
      "        [18379,   374,   264,  6424,   304, 59792,  6406,   304,   279,   549,\n",
      "           815,    13,  1614,   315, 22108,    13,  1102,  1047,   264,  7187,\n",
      "           315,   220,    23,    11, 16551,   520,   279,   220,  2366,    15,\n",
      "         44702,    13,   578,  6424,   374, 13489,   220, 54085,   315, 19441,\n",
      "         10406,   323,   374, 77317,   555, 59792,    11, 17530, 16381,    11,\n",
      "         25518, 59919,    11,  3344,  2630,    11,   323,  3344,  3195,    13,\n",
      "         22108,  1614, 11543,   220,  7743,   323,   220,  7322,  1629,  1555,\n",
      "          8384,   285,   382, 13730,   271, 18379,   574,  1176, 23183,   304,\n",
      "           220, 10680,    22,   323,   574, 19073, 32762,   304,   220,  9367,\n",
      "            20,    13,  8384,   285,   574, 13517,   961,   315, 51499,  5721,\n",
      "            11,  3156,   430,  6424, 11938,   279, 12098,   315,  8384,   285,\n",
      "            11,   323,  1023,  3118,  1938, 14932, 25861,    11,   311,  3344,\n",
      "          2630,   304,   220, 10680,    16,    13,   763]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[ 0.0386,  0.3276,  0.1686,  ..., -0.1971,  0.1848,  0.0103],\n",
      "        [-0.0101,  0.0033,  0.1051,  ...,  0.1193,  0.1124, -0.4741],\n",
      "        [ 0.1194, -0.1238,  0.2469,  ...,  0.3372,  0.1942,  0.2644],\n",
      "        ...,\n",
      "        [ 0.1299,  0.1130,  0.0597,  ..., -0.0970,  0.3091, -0.2433],\n",
      "        [ 0.1272, -0.1791, -0.0668,  ...,  0.0585, -0.1193,  0.4321],\n",
      "        [-0.2061, -0.0298, -0.1541,  ...,  0.1318,  0.0656,  0.1367]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([  791,  1274,   315, 57784,   527, 44029, 18255,  1139,  1403,  1925,\n",
      "        22277, 10977,    11, 18341,   356,  1100,   462,  2469,   323, 24666,\n",
      "          356,  1100,   462,  2469,    11,   889,  4430,  1690, 13042, 25022,\n",
      "          719, 10519, 12742, 40521,  3196,   389, 57978,    11, 13901,    11,\n",
      "         4221,    11,   323,  3345, 20405,   449, 25431,   323, 17442, 15947,\n",
      "           13, 13538,   279, 26086,  3940,   304,   220,  5162,    19,   279,\n",
      "        32538,   315, 57784,   320,  3473,   220,  2813,    13,    16,     4,\n",
      "        18341, 12365,   356,  1100,   462,  2469,    11,   220,   972,    13,\n",
      "           17,     4, 24666, 12365,   356,  1100,   462,  2469,    11,   366,\n",
      "           20,     4,  1023, 10977,    11, 15871, 39478,  5493,    11,   220,\n",
      "         2947,   263,  3695,    11,   323,  1023, 69345,     8,  1051, 77810,\n",
      "          927,   279,  4553, 13218,   382,   791, 24666, 30215,   315, 57784,\n",
      "          304,   220,  4468,    19,   409, 61596, 17071, 18379,   374,   264,\n",
      "         6424,   304, 59792,  6406,   304,   279,   549,   815,    13,  1614,\n",
      "          315, 22108,    13,  1102,  1047,   264,  7187,   315,   220,    23,\n",
      "           11, 16551,   520,   279,   220,  2366,    15, 44702,    13,   578,\n",
      "         6424,   374, 13489,   220, 54085,   315, 19441, 10406,   323,   374,\n",
      "        77317,   555, 59792,    11, 17530, 16381,    11, 25518, 59919,    11,\n",
      "         3344,  2630,    11,   323,  3344,  3195,    13, 22108,  1614, 11543,\n",
      "          220,  7743,   323,   220,  7322,  1629,  1555,  8384,   285,   382,\n",
      "        13730,   271, 18379,   574,  1176, 23183,   304,   220, 10680,    22,\n",
      "          323,   574, 19073, 32762,   304,   220,  9367,    20,    13,  8384,\n",
      "          285,   574, 13517,   961,   315, 51499,  5721,    11,  3156,   430,\n",
      "         6424, 11938,   279, 12098,   315,  8384,   285,    11,   323,  1023,\n",
      "         3118,  1938, 14932, 25861,    11,   311,  3344,  2630,   304,   220,\n",
      "        10680,    16,    13,   763], device='cuda:0')\n",
      "Epoch 0, Batch 5, Loss: 11.549735069274902\n",
      "Batch 6, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-2.5818e-02,  3.4644e-01,  2.1448e-01,  ..., -1.8811e-01,\n",
      "           1.5491e-01,  7.0923e-02],\n",
      "         [ 2.3291e-01,  3.5840e-01, -9.9365e-02,  ..., -7.7637e-02,\n",
      "           2.3523e-01, -5.8136e-02],\n",
      "         [ 2.7905e-01, -2.1594e-01,  1.6388e-02,  ...,  1.4587e-01,\n",
      "          -5.8154e-01,  5.5969e-02],\n",
      "         ...,\n",
      "         [-4.1895e-01, -1.5491e-01,  2.6587e-01,  ..., -1.4636e-01,\n",
      "           1.5350e-02,  7.4524e-02],\n",
      "         [ 1.3220e-01,  8.3862e-02, -9.0820e-02,  ..., -1.2549e-01,\n",
      "          -2.6443e-02, -3.9520e-02],\n",
      "         [-8.4229e-02, -2.7783e-01, -7.6843e-02,  ...,  3.1555e-02,\n",
      "          -1.4270e-01,  8.1970e-02]],\n",
      "\n",
      "        [[-1.2720e-04,  3.6450e-01,  2.2437e-01,  ..., -1.9482e-01,\n",
      "           1.5137e-01,  8.5571e-02],\n",
      "         [ 3.4790e-01,  6.8359e-01,  1.3940e-01,  ...,  2.5586e-01,\n",
      "           8.3618e-02,  5.9418e-02],\n",
      "         [ 9.2590e-02, -2.1802e-01,  1.6187e-01,  ..., -2.2614e-02,\n",
      "          -4.4067e-02,  3.7384e-02],\n",
      "         ...,\n",
      "         [ 2.1716e-01, -7.8491e-02,  3.7537e-02,  ...,  9.0698e-02,\n",
      "           5.2490e-02, -2.4878e-01],\n",
      "         [ 6.4453e-02, -1.8506e-01,  3.1982e-01,  ..., -3.0542e-01,\n",
      "          -9.4360e-02, -1.8030e-01],\n",
      "         [-1.4160e-01, -1.2756e-01, -4.6417e-02,  ..., -6.8665e-02,\n",
      "           1.7676e-01,  1.9067e-01]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[ 1738,    83, 75119,   374,   264,   955,   315, 14425,   331, 25489,\n",
      "         13354,   430,   737, 82829,  2958,    83, 46793,    13,  1115,   955,\n",
      "           315, 14425,   331, 25489, 46793,   374,  5950,  4908,  1606,   433,\n",
      "          5829,  1193,  1403, 75119, 63036,    25,   279,  8957, 33961,   323,\n",
      "           279,  2033, 75119, 33961,   320,    52,   815,    13, 57726,    26,\n",
      "          3967,   304,  1063,  1023,  5961,   439,  8957, 33961,   323,  4353,\n",
      "           901,   570, 10846,  1052,    83, 12912,  1511,   264,  4353,   901,\n",
      "           477, 24657, 33961, 52035,   719, 68069,  1403,  1990,   279, 12414,\n",
      "         63036,    13,  1115,   574,   311,  5471, 50971,   315,  1063, 12912,\n",
      "            13, 29625, 63036,  1005,  2753, 39347,  1109,  2033, 75119, 63036,\n",
      "            11,   902,  3135,   304,   264,  9302,  6811,   304, 11341,  1990,\n",
      "           279,  1403, 13124,   315, 33961,    13,  2958,    83, 75119,  7739,\n",
      "         12912,   555, 21973,   304,  5596,   315,   264],\n",
      "        [ 9028, 70754,  1395, 20674, 31475,  2652,  1174, 57869, 71722,    25,\n",
      "           883,   374,   264,  3363,   304, 80013, 20674, 98628,   424,   258,\n",
      "          6406,    11,   961,   315,   279, 23565,   266,  5654,   304, 99911,\n",
      "         47149,    13,  3861, 14458,    11,   622, 46931, 39204,   374, 38018,\n",
      "           555,   279,  3363,   382,   791,  3363,   374,  7559,   520,   279,\n",
      "           390, 41116,   315,   279,  9538,    72, 20674, 11188,   449,   279,\n",
      "          1369,  1395, 20674, 11188,    11,   279, 15629, 36612,   505,   279,\n",
      "           220,   132,   248,  8362,    84, 41114,    13,  2057,   279,  9909,\n",
      "            11,   433,   374,   304,  2167,  3729,   449,   279, 23565,   266,\n",
      "         25964,    13,  1102,   374,   459,  3062, 51576,  2494,    11,  1694,\n",
      "          7559, 13489,   220,  1272,  4194, 16400,   505,   279, 14189, 10954,\n",
      "            11,  1050, 28371, 21506,    64,    11,   220,  1691,  4194, 16400,\n",
      "           505,   507, 21506, 79378, 12093, 20674,    84]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0258,  0.3464,  0.2145,  ..., -0.1881,  0.1549,  0.0709],\n",
      "        [ 0.2329,  0.3584, -0.0994,  ..., -0.0776,  0.2352, -0.0581],\n",
      "        [ 0.2791, -0.2159,  0.0164,  ...,  0.1459, -0.5815,  0.0560],\n",
      "        ...,\n",
      "        [ 0.2172, -0.0785,  0.0375,  ...,  0.0907,  0.0525, -0.2488],\n",
      "        [ 0.0645, -0.1851,  0.3198,  ..., -0.3054, -0.0944, -0.1803],\n",
      "        [-0.1416, -0.1276, -0.0464,  ..., -0.0687,  0.1768,  0.1907]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([ 1738,    83, 75119,   374,   264,   955,   315, 14425,   331, 25489,\n",
      "        13354,   430,   737, 82829,  2958,    83, 46793,    13,  1115,   955,\n",
      "          315, 14425,   331, 25489, 46793,   374,  5950,  4908,  1606,   433,\n",
      "         5829,  1193,  1403, 75119, 63036,    25,   279,  8957, 33961,   323,\n",
      "          279,  2033, 75119, 33961,   320,    52,   815,    13, 57726,    26,\n",
      "         3967,   304,  1063,  1023,  5961,   439,  8957, 33961,   323,  4353,\n",
      "          901,   570, 10846,  1052,    83, 12912,  1511,   264,  4353,   901,\n",
      "          477, 24657, 33961, 52035,   719, 68069,  1403,  1990,   279, 12414,\n",
      "        63036,    13,  1115,   574,   311,  5471, 50971,   315,  1063, 12912,\n",
      "           13, 29625, 63036,  1005,  2753, 39347,  1109,  2033, 75119, 63036,\n",
      "           11,   902,  3135,   304,   264,  9302,  6811,   304, 11341,  1990,\n",
      "          279,  1403, 13124,   315, 33961,    13,  2958,    83, 75119,  7739,\n",
      "        12912,   555, 21973,   304,  5596,   315,   264,  9028, 70754,  1395,\n",
      "        20674, 31475,  2652,  1174, 57869, 71722,    25,   883,   374,   264,\n",
      "         3363,   304, 80013, 20674, 98628,   424,   258,  6406,    11,   961,\n",
      "          315,   279, 23565,   266,  5654,   304, 99911, 47149,    13,  3861,\n",
      "        14458,    11,   622, 46931, 39204,   374, 38018,   555,   279,  3363,\n",
      "          382,   791,  3363,   374,  7559,   520,   279,   390, 41116,   315,\n",
      "          279,  9538,    72, 20674, 11188,   449,   279,  1369,  1395, 20674,\n",
      "        11188,    11,   279, 15629, 36612,   505,   279,   220,   132,   248,\n",
      "         8362,    84, 41114,    13,  2057,   279,  9909,    11,   433,   374,\n",
      "          304,  2167,  3729,   449,   279, 23565,   266, 25964,    13,  1102,\n",
      "          374,   459,  3062, 51576,  2494,    11,  1694,  7559, 13489,   220,\n",
      "         1272,  4194, 16400,   505,   279, 14189, 10954,    11,  1050, 28371,\n",
      "        21506,    64,    11,   220,  1691,  4194, 16400,   505,   507, 21506,\n",
      "        79378, 12093, 20674,    84], device='cuda:0')\n",
      "Epoch 0, Batch 6, Loss: 11.553487777709961\n",
      "Batch 7, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[ 0.0341,  0.3499,  0.2211,  ..., -0.1980,  0.1852,  0.0136],\n",
      "         [ 0.0964, -0.0267,  0.0701,  ..., -0.3472, -0.0409,  0.4382],\n",
      "         [-0.2017, -0.0173, -0.0145,  ...,  0.4448,  0.0775,  0.3938],\n",
      "         ...,\n",
      "         [ 0.0474,  0.0050,  0.4004,  ...,  0.2778, -0.1376, -0.1088],\n",
      "         [ 0.1465,  0.2080, -0.1818,  ..., -0.0708,  0.1725, -0.0149],\n",
      "         [-0.2389,  0.1947,  0.2622,  ..., -0.0297,  0.2361, -0.0750]],\n",
      "\n",
      "        [[ 0.0029,  0.3579,  0.2233,  ..., -0.2192,  0.1617,  0.0571],\n",
      "         [ 0.0409,  0.2180, -0.1761,  ..., -0.3074, -0.1505,  0.2766],\n",
      "         [ 0.0341, -0.0474,  0.1758,  ..., -0.0336,  0.4446,  0.2408],\n",
      "         ...,\n",
      "         [-0.0316,  0.1875,  0.3813,  ..., -0.0372,  0.1901,  0.1761],\n",
      "         [-0.1121,  0.4287, -0.0359,  ..., -0.0839,  0.0518,  0.1957],\n",
      "         [ 0.0728, -0.1736,  0.2443,  ..., -0.5410, -0.0937,  0.0064]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[30690,  2718, 31475,   883,   374,   279,  4007,   315, 78141, 50312,\n",
      "           323, 40854,  3925,    13,  1102,  1101, 19813,   311,   279,  4526,\n",
      "           323, 35996,   315, 50312,   323,  1023, 10891,   266, 43723,  3956,\n",
      "            13,  6104, 15499,  5938,   449, 21899, 26984,   323,   279,  4007,\n",
      "           315, 78141,    11,   433,   374,  3284,   311,   387,   264, 10891,\n",
      "           266, 19784,  2085, 41377,   904, 50312,    13,  1789,  2937,    11,\n",
      "           279, 50312,  1694, 20041,  1253,   387,  1633,  9024,   477, 48383,\n",
      "          1193,   304, 51677,   382, 32960, 99174,   198,   791,  3492,   330,\n",
      "         46185,  2718,     1,   374,   279,  6498, 12215, 37822,   315,   279,\n",
      "          8753,  7492, 78718,   555, 95359,  6385, 13576,   304,   220,  9714,\n",
      "            19,    13,  6385, 13576, 11224,   430, 50312,  1047,  1027, 14890,\n",
      "           323, 20041,   369,   279,  3766,  4848,   477,  8254,  1667,   323,\n",
      "           264,  2731,   836,   574,  2631,   369,   279],\n",
      "        [  198,  1846,   220,    16,   477,   220,    16, 27809,  9149,     8,\n",
      "           374,   279, 16746,  1060,   369,   279,  1556,  2201, 21414,  6729,\n",
      "           320,  1846,     8,  9052, 13470, 11639,    11,   323,   279,   220,\n",
      "            16,   267,  1060,   315,   279,   220,    16,   267,  9478,   323,\n",
      "           220,    16,   267, 89785,   315,   279,  9052,   323,  7874, 48688,\n",
      "           320,  2152,   570,  1102,   574,   264,  4279,  1060,  6041,   389,\n",
      "          7884,   477,  7418,    11,   264,  4279,  1060,  6041,   389,  7884,\n",
      "           555,   279,   463,   273, 27330, 38897, 13470,    11,   323,   264,\n",
      "          4279,  1060,  6041,   389,  7159,   555,   279,   463,   273, 27330,\n",
      "         16431, 22865, 13470,    13,  4815,   644,   279, 13041, 21080,    11,\n",
      "          9827,   220,    16,   574,  3967,   439,   279,   330,  9679,   315,\n",
      "           279, 75289,  5383,   315,   480,  2192,   355, 54753,   323, 14103,\n",
      "          9334, 16056,   620,   355,   498,   323,  2753]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[ 0.0341,  0.3499,  0.2211,  ..., -0.1980,  0.1852,  0.0136],\n",
      "        [ 0.0964, -0.0267,  0.0701,  ..., -0.3472, -0.0409,  0.4382],\n",
      "        [-0.2017, -0.0173, -0.0145,  ...,  0.4448,  0.0775,  0.3938],\n",
      "        ...,\n",
      "        [-0.0316,  0.1875,  0.3813,  ..., -0.0372,  0.1901,  0.1761],\n",
      "        [-0.1121,  0.4287, -0.0359,  ..., -0.0839,  0.0518,  0.1957],\n",
      "        [ 0.0728, -0.1736,  0.2443,  ..., -0.5410, -0.0937,  0.0064]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([30690,  2718, 31475,   883,   374,   279,  4007,   315, 78141, 50312,\n",
      "          323, 40854,  3925,    13,  1102,  1101, 19813,   311,   279,  4526,\n",
      "          323, 35996,   315, 50312,   323,  1023, 10891,   266, 43723,  3956,\n",
      "           13,  6104, 15499,  5938,   449, 21899, 26984,   323,   279,  4007,\n",
      "          315, 78141,    11,   433,   374,  3284,   311,   387,   264, 10891,\n",
      "          266, 19784,  2085, 41377,   904, 50312,    13,  1789,  2937,    11,\n",
      "          279, 50312,  1694, 20041,  1253,   387,  1633,  9024,   477, 48383,\n",
      "         1193,   304, 51677,   382, 32960, 99174,   198,   791,  3492,   330,\n",
      "        46185,  2718,     1,   374,   279,  6498, 12215, 37822,   315,   279,\n",
      "         8753,  7492, 78718,   555, 95359,  6385, 13576,   304,   220,  9714,\n",
      "           19,    13,  6385, 13576, 11224,   430, 50312,  1047,  1027, 14890,\n",
      "          323, 20041,   369,   279,  3766,  4848,   477,  8254,  1667,   323,\n",
      "          264,  2731,   836,   574,  2631,   369,   279,   198,  1846,   220,\n",
      "           16,   477,   220,    16, 27809,  9149,     8,   374,   279, 16746,\n",
      "         1060,   369,   279,  1556,  2201, 21414,  6729,   320,  1846,     8,\n",
      "         9052, 13470, 11639,    11,   323,   279,   220,    16,   267,  1060,\n",
      "          315,   279,   220,    16,   267,  9478,   323,   220,    16,   267,\n",
      "        89785,   315,   279,  9052,   323,  7874, 48688,   320,  2152,   570,\n",
      "         1102,   574,   264,  4279,  1060,  6041,   389,  7884,   477,  7418,\n",
      "           11,   264,  4279,  1060,  6041,   389,  7884,   555,   279,   463,\n",
      "          273, 27330, 38897, 13470,    11,   323,   264,  4279,  1060,  6041,\n",
      "          389,  7159,   555,   279,   463,   273, 27330, 16431, 22865, 13470,\n",
      "           13,  4815,   644,   279, 13041, 21080,    11,  9827,   220,    16,\n",
      "          574,  3967,   439,   279,   330,  9679,   315,   279, 75289,  5383,\n",
      "          315,   480,  2192,   355, 54753,   323, 14103,  9334, 16056,   620,\n",
      "          355,   498,   323,  2753], device='cuda:0')\n",
      "Epoch 0, Batch 7, Loss: 11.5432767868042\n",
      "Batch 8, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-0.0033,  0.3572,  0.2181,  ..., -0.1948,  0.1631,  0.0567],\n",
      "         [ 0.0170,  0.0056,  0.0554,  ...,  0.1136,  0.1840, -0.4568],\n",
      "         [-0.3767, -0.2744, -0.0502,  ...,  0.0134,  0.1637, -0.0324],\n",
      "         ...,\n",
      "         [ 0.1023,  0.2849, -0.0698,  ...,  0.2534,  0.2898, -0.0493],\n",
      "         [-0.2427, -0.2563, -0.1111,  ..., -0.0217,  0.4287, -0.0088],\n",
      "         [ 0.2725,  0.2413, -0.0435,  ..., -0.1360,  0.0848,  0.2286]],\n",
      "\n",
      "        [[-0.0324,  0.3521,  0.2220,  ..., -0.1875,  0.1564,  0.0340],\n",
      "         [ 0.0952,  0.1520, -0.1605,  ..., -0.3828, -0.2151,  0.0522],\n",
      "         [-0.1555,  0.2588, -0.1512,  ..., -0.4656, -0.2605,  0.1710],\n",
      "         ...,\n",
      "         [-0.0268, -0.1050,  0.3159,  ..., -0.0687, -0.4653,  0.1548],\n",
      "         [-0.1998, -0.2380, -0.1687,  ...,  0.1307,  0.1986,  0.0787],\n",
      "         [-0.0862, -0.1519,  0.3589,  ..., -0.6201, -0.3213,  0.1949]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[  791,   735, 13005,  6570,    12,    17, 93496,  5853,   374,   264,\n",
      "          8448,  6108, 36125, 13517,  8040,   323,  9124,   555,  3778, 14290,\n",
      "           735, 13005, 59945, 13332,    13,  1102,   706,  1027, 11383,  1511,\n",
      "           439,   264, 17251,   323,  5043, 86572, 63125,  7868,   369, 15919,\n",
      "           323,  7294, 18451, 85543, 39307, 25664,   382, 40519,   315,   279,\n",
      "         93496,  5853,  1047,  1027, 33230,  2391,   279,  3389,   220,  6280,\n",
      "            15,    82,   304,  2077,   311,   264,  1715,   505,   279,  3723,\n",
      "          4273, 19574,    11,  8260,   369,   264,  7937,  2915,  5043,   323,\n",
      "         17251, 46398, 36125,   369, 15919, 25664,    13,   735, 13005,   596,\n",
      "         21142,    11, 34167, 24073,   439,   279,   735,    12,   508,    11,\n",
      "           574, 12617,  2915, 26126,    11,  6522,   311,   279, 43221,   315,\n",
      "           264,  5226,   369,   279,  8246,   315,  3116, 47728,   323,   459,\n",
      "          2926,  7309,   315,   220,   717,  5788, 59432],\n",
      "        [15000,    74,  6406,   374,   264, 14189,  7559,   304,   279, 99911,\n",
      "         13651,   315,   279,   549,   815,    13,  1614,   315, 25378,    13,\n",
      "          1666,   315,   279,   220,  2366,    15, 44702,    11,   279,  7187,\n",
      "           574,   220,  2148,    11, 21851,    13, 11699, 14189, 10954,   374,\n",
      "         25007, 57498,    13,   578, 14189,   574, 17057,  6186,   220,    20,\n",
      "            11,   220, 10750,    20,    11,   323,  7086,   369, 98479, 13327,\n",
      "          3735,    74,   382, 15000,    74,  6406,   374,   961,   315,   279,\n",
      "         53524,    11, 11672, 45878, 66794, 12299,   382, 13730,   198, 15000,\n",
      "            74,  6406,   574, 19180,   323, 17057,   505, 59174,  6406,   389,\n",
      "          6186,   220,    20,    11,   220, 10750,    20,    13,   362, 22822,\n",
      "           311,   279, 19254,  2349,   574,  1903,   389,  5587,   220,  1032,\n",
      "            11,   220, 10750,    20,    13, 11699,  4113, 23546,  1051,  3010,\n",
      "         11293,   304,  6968,   423,  1037,    11, 19051]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0033,  0.3572,  0.2181,  ..., -0.1948,  0.1631,  0.0567],\n",
      "        [ 0.0170,  0.0056,  0.0554,  ...,  0.1136,  0.1840, -0.4568],\n",
      "        [-0.3767, -0.2744, -0.0502,  ...,  0.0134,  0.1637, -0.0324],\n",
      "        ...,\n",
      "        [-0.0268, -0.1050,  0.3159,  ..., -0.0687, -0.4653,  0.1548],\n",
      "        [-0.1998, -0.2380, -0.1687,  ...,  0.1307,  0.1986,  0.0787],\n",
      "        [-0.0862, -0.1519,  0.3589,  ..., -0.6201, -0.3213,  0.1949]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([  791,   735, 13005,  6570,    12,    17, 93496,  5853,   374,   264,\n",
      "         8448,  6108, 36125, 13517,  8040,   323,  9124,   555,  3778, 14290,\n",
      "          735, 13005, 59945, 13332,    13,  1102,   706,  1027, 11383,  1511,\n",
      "          439,   264, 17251,   323,  5043, 86572, 63125,  7868,   369, 15919,\n",
      "          323,  7294, 18451, 85543, 39307, 25664,   382, 40519,   315,   279,\n",
      "        93496,  5853,  1047,  1027, 33230,  2391,   279,  3389,   220,  6280,\n",
      "           15,    82,   304,  2077,   311,   264,  1715,   505,   279,  3723,\n",
      "         4273, 19574,    11,  8260,   369,   264,  7937,  2915,  5043,   323,\n",
      "        17251, 46398, 36125,   369, 15919, 25664,    13,   735, 13005,   596,\n",
      "        21142,    11, 34167, 24073,   439,   279,   735,    12,   508,    11,\n",
      "          574, 12617,  2915, 26126,    11,  6522,   311,   279, 43221,   315,\n",
      "          264,  5226,   369,   279,  8246,   315,  3116, 47728,   323,   459,\n",
      "         2926,  7309,   315,   220,   717,  5788, 59432, 15000,    74,  6406,\n",
      "          374,   264, 14189,  7559,   304,   279, 99911, 13651,   315,   279,\n",
      "          549,   815,    13,  1614,   315, 25378,    13,  1666,   315,   279,\n",
      "          220,  2366,    15, 44702,    11,   279,  7187,   574,   220,  2148,\n",
      "           11, 21851,    13, 11699, 14189, 10954,   374, 25007, 57498,    13,\n",
      "          578, 14189,   574, 17057,  6186,   220,    20,    11,   220, 10750,\n",
      "           20,    11,   323,  7086,   369, 98479, 13327,  3735,    74,   382,\n",
      "        15000,    74,  6406,   374,   961,   315,   279, 53524,    11, 11672,\n",
      "        45878, 66794, 12299,   382, 13730,   198, 15000,    74,  6406,   574,\n",
      "        19180,   323, 17057,   505, 59174,  6406,   389,  6186,   220,    20,\n",
      "           11,   220, 10750,    20,    13,   362, 22822,   311,   279, 19254,\n",
      "         2349,   574,  1903,   389,  5587,   220,  1032,    11,   220, 10750,\n",
      "           20,    13, 11699,  4113, 23546,  1051,  3010, 11293,   304,  6968,\n",
      "          423,  1037,    11, 19051], device='cuda:0')\n",
      "Epoch 0, Batch 8, Loss: 11.596641540527344\n",
      "Batch 9, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-1.9318e-02,  3.7744e-01,  2.2168e-01,  ..., -2.3267e-01,\n",
      "           1.5234e-01,  1.1497e-02],\n",
      "         [-4.9774e-02, -5.1318e-01,  2.2607e-01,  ...,  2.6025e-01,\n",
      "           5.9619e-01, -1.1475e-01],\n",
      "         [-1.9690e-01, -4.3555e-01, -1.5112e-01,  ..., -1.1224e-01,\n",
      "           9.9548e-02, -1.8524e-02],\n",
      "         ...,\n",
      "         [-3.1519e-01,  8.1539e-05, -1.5186e-01,  ...,  5.4260e-02,\n",
      "          -1.8286e-01,  5.6213e-02],\n",
      "         [ 4.4800e-01,  4.2139e-01,  1.7542e-01,  ...,  2.1802e-01,\n",
      "           1.0691e-03,  3.2300e-01],\n",
      "         [-9.9121e-02,  7.5256e-02,  5.7129e-01,  ..., -1.6370e-01,\n",
      "           4.9896e-02,  1.1560e-01]],\n",
      "\n",
      "        [[-7.2021e-03,  3.4399e-01,  2.1594e-01,  ..., -2.1338e-01,\n",
      "           1.9800e-01,  7.3730e-02],\n",
      "         [-2.4072e-01, -2.8467e-01, -1.5002e-01,  ..., -4.9103e-02,\n",
      "           1.8250e-01,  3.6572e-01],\n",
      "         [-4.2163e-01,  3.8696e-01,  4.0680e-02,  ..., -9.8877e-02,\n",
      "          -9.7534e-02,  6.8359e-02],\n",
      "         ...,\n",
      "         [ 1.4319e-01, -8.2350e-04,  1.8115e-01,  ...,  1.5967e-01,\n",
      "           7.0679e-02,  1.3855e-01],\n",
      "         [-1.0071e-01,  8.4412e-02,  1.1243e-01,  ..., -1.0590e-02,\n",
      "          -1.4136e-01,  1.1053e-01],\n",
      "         [ 1.3269e-01,  3.7866e-01, -8.9600e-02,  ...,  2.3010e-01,\n",
      "           3.5254e-01, -5.5511e-02]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[13129, 12968,  8316,   527,   279,  8316,   315, 19179,  1511,   304,\n",
      "         97382,   477,  4595, 52189,    13, 46560,  3666,  7133,  8316,   527,\n",
      "          2204,   505, 11537, 18767,  8316,  1606,   814,  1051,  9749,   304,\n",
      "           279,  4216,  2919,   315, 18991,    13, 18056,  1455, 18991,   374,\n",
      "          7528,  1457,    11,   279,  2362,  3878,   323,  8316,   617, 54095,\n",
      "           382, 13461,  3582,  1521,  8316,   527,   682,  1633,  2678,    11,\n",
      "          4028,   264,  1584,   315,  1194,   814,   923,   709,  6288,    13,\n",
      "         15323, 36807,  1778,   439, 79128,  1495, 13517,   304,   955,   315,\n",
      "           832,  5089,   304,   955,   315,  2500,   690,  1121,   304,  4339,\n",
      "          7366,   505,   832,  1584,   311,   279,  1828,    11, 13239,   304,\n",
      "           682, 21522,   315,  4595, 52189,  6103,   320, 70940,    13, 36617,\n",
      "            11,  9923,  4336,   323,   477, 85411,    11, 69627, 12920,    11,\n",
      "           323, 90660, 78888,   570, 13538,   279,  5526],\n",
      "        [57051,  5960, 55500, 20267,  1995,   983,   301,   374,   264, 15506,\n",
      "          9131,   304,  5960, 55500,    11,  7188,    13,  1102,   574, 18538,\n",
      "           304,   220, 10562,    22,   439,   264,  6593,   439, 89300,  3573,\n",
      "          2008,  1474,  7711,   909,   315, 24098,  5960, 13175,   409,  1666,\n",
      "         24315,    13,  1102,   574,   264,  8952,   311,  4322, 14363, 17118,\n",
      "          9053,    11,  3339,   433, 83160,  7188,   596,  1176,  8528, 12635,\n",
      "          2411,    13,   578,  9282,   574,  1790,  2731,  1109,   304,  5960,\n",
      "         13175,    11,   902,  9087,   279,  5986,   636,  2731,    13,   220,\n",
      "          1102,   574,   539, 10825,   311,   387,   264,  2559, 74249,  9131,\n",
      "            11,   719, 38330, 14264,   323, 29761,   291,   323,   574, 11938,\n",
      "          2539,  9131,  2704,   389,  6664,   220,   777,    11,   220, 10828,\n",
      "            17,   382, 13730,   198, 24098,  5960, 55500, 20267,  1995,   983,\n",
      "           301,   574, 18538,   389,  6790,   220,   975]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0193,  0.3774,  0.2217,  ..., -0.2327,  0.1523,  0.0115],\n",
      "        [-0.0498, -0.5132,  0.2261,  ...,  0.2603,  0.5962, -0.1147],\n",
      "        [-0.1969, -0.4355, -0.1511,  ..., -0.1122,  0.0995, -0.0185],\n",
      "        ...,\n",
      "        [ 0.1432, -0.0008,  0.1812,  ...,  0.1597,  0.0707,  0.1385],\n",
      "        [-0.1007,  0.0844,  0.1124,  ..., -0.0106, -0.1414,  0.1105],\n",
      "        [ 0.1327,  0.3787, -0.0896,  ...,  0.2301,  0.3525, -0.0555]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([13129, 12968,  8316,   527,   279,  8316,   315, 19179,  1511,   304,\n",
      "        97382,   477,  4595, 52189,    13, 46560,  3666,  7133,  8316,   527,\n",
      "         2204,   505, 11537, 18767,  8316,  1606,   814,  1051,  9749,   304,\n",
      "          279,  4216,  2919,   315, 18991,    13, 18056,  1455, 18991,   374,\n",
      "         7528,  1457,    11,   279,  2362,  3878,   323,  8316,   617, 54095,\n",
      "          382, 13461,  3582,  1521,  8316,   527,   682,  1633,  2678,    11,\n",
      "         4028,   264,  1584,   315,  1194,   814,   923,   709,  6288,    13,\n",
      "        15323, 36807,  1778,   439, 79128,  1495, 13517,   304,   955,   315,\n",
      "          832,  5089,   304,   955,   315,  2500,   690,  1121,   304,  4339,\n",
      "         7366,   505,   832,  1584,   311,   279,  1828,    11, 13239,   304,\n",
      "          682, 21522,   315,  4595, 52189,  6103,   320, 70940,    13, 36617,\n",
      "           11,  9923,  4336,   323,   477, 85411,    11, 69627, 12920,    11,\n",
      "          323, 90660, 78888,   570, 13538,   279,  5526, 57051,  5960, 55500,\n",
      "        20267,  1995,   983,   301,   374,   264, 15506,  9131,   304,  5960,\n",
      "        55500,    11,  7188,    13,  1102,   574, 18538,   304,   220, 10562,\n",
      "           22,   439,   264,  6593,   439, 89300,  3573,  2008,  1474,  7711,\n",
      "          909,   315, 24098,  5960, 13175,   409,  1666, 24315,    13,  1102,\n",
      "          574,   264,  8952,   311,  4322, 14363, 17118,  9053,    11,  3339,\n",
      "          433, 83160,  7188,   596,  1176,  8528, 12635,  2411,    13,   578,\n",
      "         9282,   574,  1790,  2731,  1109,   304,  5960, 13175,    11,   902,\n",
      "         9087,   279,  5986,   636,  2731,    13,   220,  1102,   574,   539,\n",
      "        10825,   311,   387,   264,  2559, 74249,  9131,    11,   719, 38330,\n",
      "        14264,   323, 29761,   291,   323,   574, 11938,  2539,  9131,  2704,\n",
      "          389,  6664,   220,   777,    11,   220, 10828,    17,   382, 13730,\n",
      "          198, 24098,  5960, 55500, 20267,  1995,   983,   301,   574, 18538,\n",
      "          389,  6790,   220,   975], device='cuda:0')\n",
      "Epoch 0, Batch 9, Loss: 11.523929595947266\n",
      "Batch 10, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-0.0514,  0.3372,  0.2161,  ..., -0.2356,  0.1268,  0.0615],\n",
      "         [-0.3328,  0.0505, -0.0972,  ..., -0.4795,  0.3589, -0.2888],\n",
      "         [-0.1288, -0.1167,  0.2664,  ..., -0.6499, -0.3362,  0.1509],\n",
      "         ...,\n",
      "         [-0.2971, -0.0084, -0.1533,  ..., -0.3208,  0.3850,  0.0869],\n",
      "         [-0.2622,  0.2130,  0.1565,  ...,  0.0848,  0.1458, -0.1521],\n",
      "         [ 0.1238,  0.3032, -0.1032,  ...,  0.2026,  0.3582, -0.0717]],\n",
      "\n",
      "        [[-0.0077,  0.3674,  0.2253,  ..., -0.1935,  0.1511,  0.0378],\n",
      "         [-0.2236, -0.1814,  0.2440,  ..., -0.4712,  0.1479,  0.3123],\n",
      "         [ 0.2998,  0.4734,  0.3408,  ..., -0.3147,  0.0545, -0.2291],\n",
      "         ...,\n",
      "         [-0.1465, -0.2175, -0.0285,  ...,  0.1602, -0.0050, -0.0515],\n",
      "         [-0.0764,  0.0148,  0.5322,  ..., -0.1224,  0.0811,  0.1327],\n",
      "         [-0.2356,  0.1418, -0.0014,  ...,  0.3088, -0.1149,  0.0438]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[37031,    11,   279,  1917,   596,  2132, 68067,  3224,   304,  2860,\n",
      "          3158,    11,   374, 12514,   311,  3515,   459, 11297,    11,  1579,\n",
      "         37789,  4107, 80149, 58697, 18386, 56886,  3629, 13057, 27650,  1990,\n",
      "          5933,  5211, 33289,  6732,    11, 29149,   323, 16036,  5789,    13,\n",
      "          7008,   596, 18386,  1887,  5764,   810,  1109,   220,   315, 19795,\n",
      "            11,   220,   605,  3682,  6625, 46163,    11,   220,  3101,  9333,\n",
      "         46163,    11,   220,   315, 31301, 40106,  3839,    11,   323,   810,\n",
      "          1109,   220,  3101,  8518, 20946,   323, 69566,  2530,   430,  3493,\n",
      "          2680,   311,   279, 16867,    11, 23179,   323, 37518, 54280,   439,\n",
      "          1664,   439,   279,  8681, 42679,   323,   279,   800,    13, 28574,\n",
      "          1369, 14075,    13,   763,   220,  1049,    20,    11,   279, 18386,\n",
      "         10706,  1903,   709,   220,    19,    13,    17,     4,   315,  7008,\n",
      "           596, 30830,    11,  7863,   311,   220,    18],\n",
      "        [ 9619, 37733,   320,   883,   374,   264,  3363,  7559,   304, 18671,\n",
      "         22725,  6406,    11,  7188,    11,  3723,  4273,    13,  1666,   315,\n",
      "           279,   220,  2366,    15, 44702,    11,   279,  3363,  1047,   264,\n",
      "          2860,  7187,   315,   220, 10290,    11, 21717,   382,  9619, 37733,\n",
      "           574, 18538,   304,   220,  9367,    22,    13,  1102, 27528,   279,\n",
      "          4363,   389, 17981,   315,   279,  2468,   331,  3416,    11,  2057,\n",
      "           375,  4657,   323, 16376,  3926, 55556,    13, 22425,  2740,   433,\n",
      "           574,   264,  4219,   315, 30029,    11, 35146, 10707,  2396,   315,\n",
      "         61349, 85138,   323,  1023, 60290, 31665,    26, 60063, 33289,    26,\n",
      "         18386,    26,   323, 15266,    13,  1102,   374,  2162,   311, 12387,\n",
      "          5190, 16627, 14673,    11,  8104,  7188,  3314,  3907,    11,  8797,\n",
      "         37733,   323,  8797, 37733,  9304,    13,  5659,   279,  5209,    12,\n",
      "          6393,    15,    82,  1555,   279,  3389,   220]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0514,  0.3372,  0.2161,  ..., -0.2356,  0.1268,  0.0615],\n",
      "        [-0.3328,  0.0505, -0.0972,  ..., -0.4795,  0.3589, -0.2888],\n",
      "        [-0.1288, -0.1167,  0.2664,  ..., -0.6499, -0.3362,  0.1509],\n",
      "        ...,\n",
      "        [-0.1465, -0.2175, -0.0285,  ...,  0.1602, -0.0050, -0.0515],\n",
      "        [-0.0764,  0.0148,  0.5322,  ..., -0.1224,  0.0811,  0.1327],\n",
      "        [-0.2356,  0.1418, -0.0014,  ...,  0.3088, -0.1149,  0.0438]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([37031,    11,   279,  1917,   596,  2132, 68067,  3224,   304,  2860,\n",
      "         3158,    11,   374, 12514,   311,  3515,   459, 11297,    11,  1579,\n",
      "        37789,  4107, 80149, 58697, 18386, 56886,  3629, 13057, 27650,  1990,\n",
      "         5933,  5211, 33289,  6732,    11, 29149,   323, 16036,  5789,    13,\n",
      "         7008,   596, 18386,  1887,  5764,   810,  1109,   220,   315, 19795,\n",
      "           11,   220,   605,  3682,  6625, 46163,    11,   220,  3101,  9333,\n",
      "        46163,    11,   220,   315, 31301, 40106,  3839,    11,   323,   810,\n",
      "         1109,   220,  3101,  8518, 20946,   323, 69566,  2530,   430,  3493,\n",
      "         2680,   311,   279, 16867,    11, 23179,   323, 37518, 54280,   439,\n",
      "         1664,   439,   279,  8681, 42679,   323,   279,   800,    13, 28574,\n",
      "         1369, 14075,    13,   763,   220,  1049,    20,    11,   279, 18386,\n",
      "        10706,  1903,   709,   220,    19,    13,    17,     4,   315,  7008,\n",
      "          596, 30830,    11,  7863,   311,   220,    18,  9619, 37733,   320,\n",
      "          883,   374,   264,  3363,  7559,   304, 18671, 22725,  6406,    11,\n",
      "         7188,    11,  3723,  4273,    13,  1666,   315,   279,   220,  2366,\n",
      "           15, 44702,    11,   279,  3363,  1047,   264,  2860,  7187,   315,\n",
      "          220, 10290,    11, 21717,   382,  9619, 37733,   574, 18538,   304,\n",
      "          220,  9367,    22,    13,  1102, 27528,   279,  4363,   389, 17981,\n",
      "          315,   279,  2468,   331,  3416,    11,  2057,   375,  4657,   323,\n",
      "        16376,  3926, 55556,    13, 22425,  2740,   433,   574,   264,  4219,\n",
      "          315, 30029,    11, 35146, 10707,  2396,   315, 61349, 85138,   323,\n",
      "         1023, 60290, 31665,    26, 60063, 33289,    26, 18386,    26,   323,\n",
      "        15266,    13,  1102,   374,  2162,   311, 12387,  5190, 16627, 14673,\n",
      "           11,  8104,  7188,  3314,  3907,    11,  8797, 37733,   323,  8797,\n",
      "        37733,  9304,    13,  5659,   279,  5209,    12,  6393,    15,    82,\n",
      "         1555,   279,  3389,   220], device='cuda:0')\n",
      "Epoch 0, Batch 10, Loss: 11.549274444580078\n",
      "Batch 11, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-0.0158,  0.3738,  0.2136,  ..., -0.1985,  0.1732,  0.0854],\n",
      "         [-0.0520, -0.1926, -0.0349,  ...,  0.1515,  0.3623,  0.2793],\n",
      "         [-0.0819,  0.4419,  0.0036,  ..., -0.0573, -0.3625,  0.0462],\n",
      "         ...,\n",
      "         [-0.0497, -0.4160, -0.2888,  ...,  0.3076, -0.0348,  0.0464],\n",
      "         [-0.0439,  0.0821,  0.2123,  ...,  0.0397, -0.2793, -0.1148],\n",
      "         [-0.1065,  0.0574,  0.2173,  ...,  0.2944,  0.0322,  0.2482]],\n",
      "\n",
      "        [[-0.0279,  0.3979,  0.2125,  ..., -0.2345,  0.1539,  0.0541],\n",
      "         [ 0.0077,  0.1060,  0.2340,  ..., -0.1561,  0.2690,  0.2537],\n",
      "         [ 0.0566,  0.1493,  0.2072,  ..., -0.1722, -0.1121,  0.2695],\n",
      "         ...,\n",
      "         [ 0.4175,  0.1680,  0.1147,  ..., -0.3315,  0.2661,  0.2427],\n",
      "         [-0.3501,  0.1807,  0.2527,  ..., -0.0397,  0.1975, -0.0635],\n",
      "         [ 0.0749,  0.0983,  0.0080,  ...,  0.2903,  0.1995,  0.3701]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[26691, 49927,   304,   279,  3723,  4273,  6137,   304,   279,   220,\n",
      "          7285,    15,    82,   520, 24490,   323, 72001, 76249, 20462, 45966,\n",
      "           596, 22772,  8216,    11,   468,    17, 53437,    45,    13,   220,\n",
      "           578,  1005,   315, 24342,  9063,   706,  1027,  5938,   449,  5190,\n",
      "          5222,  4367,   304,  4731,  9063,   382, 13730,   315, 24342,  9063,\n",
      "           304,   279,   549,   815,   382,   644,   279,  3723,  4273,    11,\n",
      "         24342, 49927, 17789,  5131,   527, 12893,   311,   220,  4645, 12006,\n",
      "            11, 24073,   220,  4044,    13,    24,   311,   220,  7699,    13,\n",
      "            24,  4194, 38592,    11,  2949,   264,   220,   508,    13,    17,\n",
      "          4194, 38592, 25480, 11900,  7200,    11, 56886,   220,  4044,    13,\n",
      "            23,  4235,  6640,    13,    15,  4194, 38592,   382,   644,   279,\n",
      "           220,  7285,    15,    82, 26969,  1051, 22088,  1139, 31692,  9063,\n",
      "         17789, 78768,   389,   330, 26840,  5234, 43480],\n",
      "        [   39,   830,  3817,   374,   264, 14458,   304, 18561, 64377, 60347,\n",
      "            11, 29974,    11,  3723,  4273,    13,   578,  7187,   574,   220,\n",
      "         13078,   520,   279,   220,  1049,    15, 44702,    13,  1102,   374,\n",
      "           961,   315,   279, 23754,   268, 28095, 31611, 66794, 12299,   382,\n",
      "          1966,  5936,   220,    20,    11,   220,   679,    18,    11, 11969,\n",
      "           555,   264,  4850,   315,   220,  1135,    12,   966, 32230, 22868,\n",
      "         55158, 40788,  1543,    11,   264, 24846,    11,   505,  5274,    13,\n",
      "          2360,  9322, 15337,   311,  5266,   279, 17352,   596,  5274,   304,\n",
      "           264,  3361,  6355, 13847,   369,  6664,   220,   777,    13,  3277,\n",
      "         26559, 78881,    11,   279,  9540, 40904, 12336,  7957,   320, 16381,\n",
      "          7552,   220,  6280,    21,     8, 13019,   369, 17352,  2085, 14076,\n",
      "           304,   279,  6664,   220,   777,  6355,   382, 13730,   271,    39,\n",
      "           830,  3817,   374,  7086,   369, 21272, 10068]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0158,  0.3738,  0.2136,  ..., -0.1985,  0.1732,  0.0854],\n",
      "        [-0.0520, -0.1926, -0.0349,  ...,  0.1515,  0.3623,  0.2793],\n",
      "        [-0.0819,  0.4419,  0.0036,  ..., -0.0573, -0.3625,  0.0462],\n",
      "        ...,\n",
      "        [ 0.4175,  0.1680,  0.1147,  ..., -0.3315,  0.2661,  0.2427],\n",
      "        [-0.3501,  0.1807,  0.2527,  ..., -0.0397,  0.1975, -0.0635],\n",
      "        [ 0.0749,  0.0983,  0.0080,  ...,  0.2903,  0.1995,  0.3701]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([26691, 49927,   304,   279,  3723,  4273,  6137,   304,   279,   220,\n",
      "         7285,    15,    82,   520, 24490,   323, 72001, 76249, 20462, 45966,\n",
      "          596, 22772,  8216,    11,   468,    17, 53437,    45,    13,   220,\n",
      "          578,  1005,   315, 24342,  9063,   706,  1027,  5938,   449,  5190,\n",
      "         5222,  4367,   304,  4731,  9063,   382, 13730,   315, 24342,  9063,\n",
      "          304,   279,   549,   815,   382,   644,   279,  3723,  4273,    11,\n",
      "        24342, 49927, 17789,  5131,   527, 12893,   311,   220,  4645, 12006,\n",
      "           11, 24073,   220,  4044,    13,    24,   311,   220,  7699,    13,\n",
      "           24,  4194, 38592,    11,  2949,   264,   220,   508,    13,    17,\n",
      "         4194, 38592, 25480, 11900,  7200,    11, 56886,   220,  4044,    13,\n",
      "           23,  4235,  6640,    13,    15,  4194, 38592,   382,   644,   279,\n",
      "          220,  7285,    15,    82, 26969,  1051, 22088,  1139, 31692,  9063,\n",
      "        17789, 78768,   389,   330, 26840,  5234, 43480,    39,   830,  3817,\n",
      "          374,   264, 14458,   304, 18561, 64377, 60347,    11, 29974,    11,\n",
      "         3723,  4273,    13,   578,  7187,   574,   220, 13078,   520,   279,\n",
      "          220,  1049,    15, 44702,    13,  1102,   374,   961,   315,   279,\n",
      "        23754,   268, 28095, 31611, 66794, 12299,   382,  1966,  5936,   220,\n",
      "           20,    11,   220,   679,    18,    11, 11969,   555,   264,  4850,\n",
      "          315,   220,  1135,    12,   966, 32230, 22868, 55158, 40788,  1543,\n",
      "           11,   264, 24846,    11,   505,  5274,    13,  2360,  9322, 15337,\n",
      "          311,  5266,   279, 17352,   596,  5274,   304,   264,  3361,  6355,\n",
      "        13847,   369,  6664,   220,   777,    13,  3277, 26559, 78881,    11,\n",
      "          279,  9540, 40904, 12336,  7957,   320, 16381,  7552,   220,  6280,\n",
      "           21,     8, 13019,   369, 17352,  2085, 14076,   304,   279,  6664,\n",
      "          220,   777,  6355,   382, 13730,   271,    39,   830,  3817,   374,\n",
      "         7086,   369, 21272, 10068], device='cuda:0')\n",
      "Epoch 0, Batch 11, Loss: 11.551765441894531\n",
      "Batch 12, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-0.0299,  0.3542,  0.2397,  ..., -0.2290,  0.1747,  0.0329],\n",
      "         [ 0.0028, -0.0424,  0.1844,  ...,  0.3613,  0.4585,  0.1963],\n",
      "         [-0.0699,  0.1713, -0.2532,  ...,  0.1743, -0.0836,  0.5308],\n",
      "         ...,\n",
      "         [-0.0651,  0.1081, -0.0848,  ...,  0.0966,  0.0983, -0.3330],\n",
      "         [-0.3320,  0.1350, -0.0504,  ...,  0.0344, -0.0406,  0.3047],\n",
      "         [-0.0346,  0.0789,  0.2401,  ..., -0.2057, -0.0100, -0.1423]],\n",
      "\n",
      "        [[-0.0058,  0.3264,  0.2371,  ..., -0.2050,  0.1368,  0.0157],\n",
      "         [ 0.2144,  0.0042, -0.2061,  ...,  0.2676,  0.0926,  0.4890],\n",
      "         [-0.0108, -0.0782, -0.0649,  ..., -0.1357,  0.0751,  0.1443],\n",
      "         ...,\n",
      "         [ 0.0521,  0.2554,  0.0978,  ..., -0.0178, -0.3188,  0.1810],\n",
      "         [-0.2195, -0.0998,  0.2654,  ..., -0.3435, -0.1030, -0.0316],\n",
      "         [ 0.1047, -0.1721,  0.2273,  ...,  0.0559,  0.1412, -0.0549]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[51290,  8563, 16645, 22806,  3212, 61446,  6969,   356,  5484, 21539,\n",
      "         28816,   220,   320,   605,  6250,   220,  9378,    15,  4194,  4235,\n",
      "           220,  1313,  5887,   220,  4468,    21,     8,   574,   264,  8013,\n",
      "         39211, 16549,   323,  9640,   304,   279,  8013, 13309,    13,  6193,\n",
      "           279,  3388,   315,   813,  7076,    11,   568, 10434,   439, 10783,\n",
      "           315,  2225,   279,  5165, 16730,   315, 23782,   323,  7295, 16730,\n",
      "            11, 10783, 59082,   315,   279, 66102,  5848, 24507,   315,  6890,\n",
      "            11,   323,   279, 19533,   323, 16958,  7746, 10783,   315,   279,\n",
      "         10181,   315, 66102,  2508,   304,  7295,    11,   304,  5369,   311,\n",
      "          4477, 17510, 42117,  6603,   389, 69637, 15223,   382, 59204,   304,\n",
      "         43997,   311,   264,  6278, 15144,  3070,    11, 61446,   574,  9408,\n",
      "         14090,   304, 51327,  1603,  7366,   311,  7295,   304,   813, 34268,\n",
      "          1667,    13,  4740, 21630, 53805,   520,  3907],\n",
      "        [  271,  8059,   271,  4808,    12,  6330,    15,   198,   220, 19695,\n",
      "          1389, 87987,   540,   561,   706, 41159,   268,  9334, 16689, 11104,\n",
      "         13041, 35414,   627,   220, 24866,  1389, 16506,   315,   622,   833,\n",
      "          1974,    25,   469,  6091,    79,  4748, 69869, 15274,   279, 40202,\n",
      "          3221,   279, 11681,   783,  6424,   315,   622,   833,  1974,   627,\n",
      "          8190,    23,  1389, 16506,   315,   279, 12028,  1990, 19627,   323,\n",
      "          9635,   627, 10410,    20,  1389,   578, 16506,   315, 29071, 20069,\n",
      "          8771, 13980,    26, 12131, 14767,  8898,    11, 36024,   279,   842,\n",
      "           315,   279,  4783,   315, 18317,  8703,   295,   627,  9992,    24,\n",
      "          1389, 15506,  5438, 61378, 29627,   337,   316,   978, 30474, 27564,\n",
      "           374, 12800,   369,  1077, 65741,   382,  6330,    16,  4235,  7028,\n",
      "            15,   198, 10718,    19,  1389,   435,  7211, 73370,   331,   549,\n",
      "         34754,    25, 17420,   527, 67331,   505, 56284]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0299,  0.3542,  0.2397,  ..., -0.2290,  0.1747,  0.0329],\n",
      "        [ 0.0028, -0.0424,  0.1844,  ...,  0.3613,  0.4585,  0.1963],\n",
      "        [-0.0699,  0.1713, -0.2532,  ...,  0.1743, -0.0836,  0.5308],\n",
      "        ...,\n",
      "        [ 0.0521,  0.2554,  0.0978,  ..., -0.0178, -0.3188,  0.1810],\n",
      "        [-0.2195, -0.0998,  0.2654,  ..., -0.3435, -0.1030, -0.0316],\n",
      "        [ 0.1047, -0.1721,  0.2273,  ...,  0.0559,  0.1412, -0.0549]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([51290,  8563, 16645, 22806,  3212, 61446,  6969,   356,  5484, 21539,\n",
      "        28816,   220,   320,   605,  6250,   220,  9378,    15,  4194,  4235,\n",
      "          220,  1313,  5887,   220,  4468,    21,     8,   574,   264,  8013,\n",
      "        39211, 16549,   323,  9640,   304,   279,  8013, 13309,    13,  6193,\n",
      "          279,  3388,   315,   813,  7076,    11,   568, 10434,   439, 10783,\n",
      "          315,  2225,   279,  5165, 16730,   315, 23782,   323,  7295, 16730,\n",
      "           11, 10783, 59082,   315,   279, 66102,  5848, 24507,   315,  6890,\n",
      "           11,   323,   279, 19533,   323, 16958,  7746, 10783,   315,   279,\n",
      "        10181,   315, 66102,  2508,   304,  7295,    11,   304,  5369,   311,\n",
      "         4477, 17510, 42117,  6603,   389, 69637, 15223,   382, 59204,   304,\n",
      "        43997,   311,   264,  6278, 15144,  3070,    11, 61446,   574,  9408,\n",
      "        14090,   304, 51327,  1603,  7366,   311,  7295,   304,   813, 34268,\n",
      "         1667,    13,  4740, 21630, 53805,   520,  3907,   271,  8059,   271,\n",
      "         4808,    12,  6330,    15,   198,   220, 19695,  1389, 87987,   540,\n",
      "          561,   706, 41159,   268,  9334, 16689, 11104, 13041, 35414,   627,\n",
      "          220, 24866,  1389, 16506,   315,   622,   833,  1974,    25,   469,\n",
      "         6091,    79,  4748, 69869, 15274,   279, 40202,  3221,   279, 11681,\n",
      "          783,  6424,   315,   622,   833,  1974,   627,  8190,    23,  1389,\n",
      "        16506,   315,   279, 12028,  1990, 19627,   323,  9635,   627, 10410,\n",
      "           20,  1389,   578, 16506,   315, 29071, 20069,  8771, 13980,    26,\n",
      "        12131, 14767,  8898,    11, 36024,   279,   842,   315,   279,  4783,\n",
      "          315, 18317,  8703,   295,   627,  9992,    24,  1389, 15506,  5438,\n",
      "        61378, 29627,   337,   316,   978, 30474, 27564,   374, 12800,   369,\n",
      "         1077, 65741,   382,  6330,    16,  4235,  7028,    15,   198, 10718,\n",
      "           19,  1389,   435,  7211, 73370,   331,   549, 34754,    25, 17420,\n",
      "          527, 67331,   505, 56284], device='cuda:0')\n",
      "Epoch 0, Batch 12, Loss: 11.579294204711914\n",
      "Batch 13, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-0.0031,  0.3323,  0.2465,  ..., -0.1927,  0.1458,  0.0244],\n",
      "         [-0.0060,  0.2000,  0.0553,  ...,  0.1832,  0.3093, -0.1160],\n",
      "         [-0.0471, -0.1086,  0.1896,  ..., -0.1630, -0.0862,  0.1313],\n",
      "         ...,\n",
      "         [ 0.1024,  0.3389, -0.0565,  ..., -0.1302,  0.0345,  0.0605],\n",
      "         [ 0.0286,  0.5649,  0.1984,  ..., -0.2291, -0.0887, -0.1855],\n",
      "         [ 0.3977, -0.1731,  0.0908,  ..., -0.2988, -0.0925, -0.0455]],\n",
      "\n",
      "        [[-0.0471,  0.3535,  0.2080,  ..., -0.1959,  0.1924,  0.0498],\n",
      "         [-0.3096,  0.4324, -0.2615,  ...,  0.0859,  0.1635,  0.0419],\n",
      "         [-0.1713,  0.0251,  0.1327,  ..., -0.0558,  0.0164,  0.0218],\n",
      "         ...,\n",
      "         [ 0.0442, -0.1296, -0.2722,  ...,  0.3689, -0.2356,  0.2175],\n",
      "         [ 0.2646,  0.1664,  0.1201,  ...,  0.4763,  0.3989,  0.0267],\n",
      "         [ 0.0550,  0.2291, -0.1913,  ..., -0.3875, -0.1332,  0.2542]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[ 5176,  3168,  6798, 13011,   220,   374,   459,   653,  2910, 39382,\n",
      "           660,  4029,   220,   323, 44702, 47117,   660,  2035,   320,  6620,\n",
      "            47,     8,  7559,  2949, 80351, 53767,   304,  3206, 33780,  6406,\n",
      "            11,   304,   279,   549,   815,    13,  1614,   315,  1561, 16228,\n",
      "            13,  1666,   315,   279,   220,   679,    15,   549,   815,    13,\n",
      "         44702,    11,   279,   356, 10510,   596,  7187,   574,   220,    18,\n",
      "            11,  6393,   382, 13730,   271,    44,   460, 16965, 53767,   574,\n",
      "         32762,   389,  7552,   220,  1419,    11,   220,  9741,    22,    13,\n",
      "          1115,  5343,   264, 13651,   315,   386,  1810,  1169,   785,  5236,\n",
      "           320,  3409, 89454, 16965, 85303,   705,   264, 13651, 36608,    13,\n",
      "         64912,   320,  1466,  3690,  7730, 83353,   304,   220,  9378,    15,\n",
      "             8,   323, 89454, 16965,   320,   269,   330, 11836, 32005,     1,\n",
      "           477, 89454, 16965,  5236,     8, 11573,    13],\n",
      "        [   32, 58629, 28974,    11, 17037,  3967,   439,   264,  1207,    11,\n",
      "         11640,   351,   648,   320, 90524, 58506,  3158,   323, 11104, 20355,\n",
      "          6498,   705, 12084,   320,  3648,  4356,  4409,  6498,   705, 15155,\n",
      "           220,   320,  6334,    68,  6498,   705, 46641,   320,  3648,  9635,\n",
      "          6498,   705, 64785,   320, 24188, 15163,    11, 12551,   705,   477,\n",
      "           264,   993,  1983,   648,   320, 65432,  6498,   705,   374,   264,\n",
      "           955,   315,  3778,  9439,   477,  4106, 28974,  1903,   505,   264,\n",
      "         79610, 16385,  6638,  6859,  3160,  4583,   323, 10409,   449, 63875,\n",
      "            11, 98564,    11, 24822,    11,   323,  9955, 12843,   382,   791,\n",
      "          3878, 58629,   323,  1207,   527, 24716,   304,   279,  2326,   323,\n",
      "           539, 90547,   311,   904,  3738,   961,    11,  3582,  1690,   315,\n",
      "           279, 44589,  3878,   527, 93858,   304,   279, 87244,  3723,  4273,\n",
      "           382, 13730,   323,  1880, 99174,   198,   791]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0031,  0.3323,  0.2465,  ..., -0.1927,  0.1458,  0.0244],\n",
      "        [-0.0060,  0.2000,  0.0553,  ...,  0.1832,  0.3093, -0.1160],\n",
      "        [-0.0471, -0.1086,  0.1896,  ..., -0.1630, -0.0862,  0.1313],\n",
      "        ...,\n",
      "        [ 0.0442, -0.1296, -0.2722,  ...,  0.3689, -0.2356,  0.2175],\n",
      "        [ 0.2646,  0.1664,  0.1201,  ...,  0.4763,  0.3989,  0.0267],\n",
      "        [ 0.0550,  0.2291, -0.1913,  ..., -0.3875, -0.1332,  0.2542]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([ 5176,  3168,  6798, 13011,   220,   374,   459,   653,  2910, 39382,\n",
      "          660,  4029,   220,   323, 44702, 47117,   660,  2035,   320,  6620,\n",
      "           47,     8,  7559,  2949, 80351, 53767,   304,  3206, 33780,  6406,\n",
      "           11,   304,   279,   549,   815,    13,  1614,   315,  1561, 16228,\n",
      "           13,  1666,   315,   279,   220,   679,    15,   549,   815,    13,\n",
      "        44702,    11,   279,   356, 10510,   596,  7187,   574,   220,    18,\n",
      "           11,  6393,   382, 13730,   271,    44,   460, 16965, 53767,   574,\n",
      "        32762,   389,  7552,   220,  1419,    11,   220,  9741,    22,    13,\n",
      "         1115,  5343,   264, 13651,   315,   386,  1810,  1169,   785,  5236,\n",
      "          320,  3409, 89454, 16965, 85303,   705,   264, 13651, 36608,    13,\n",
      "        64912,   320,  1466,  3690,  7730, 83353,   304,   220,  9378,    15,\n",
      "            8,   323, 89454, 16965,   320,   269,   330, 11836, 32005,     1,\n",
      "          477, 89454, 16965,  5236,     8, 11573,    13,    32, 58629, 28974,\n",
      "           11, 17037,  3967,   439,   264,  1207,    11, 11640,   351,   648,\n",
      "          320, 90524, 58506,  3158,   323, 11104, 20355,  6498,   705, 12084,\n",
      "          320,  3648,  4356,  4409,  6498,   705, 15155,   220,   320,  6334,\n",
      "           68,  6498,   705, 46641,   320,  3648,  9635,  6498,   705, 64785,\n",
      "          320, 24188, 15163,    11, 12551,   705,   477,   264,   993,  1983,\n",
      "          648,   320, 65432,  6498,   705,   374,   264,   955,   315,  3778,\n",
      "         9439,   477,  4106, 28974,  1903,   505,   264, 79610, 16385,  6638,\n",
      "         6859,  3160,  4583,   323, 10409,   449, 63875,    11, 98564,    11,\n",
      "        24822,    11,   323,  9955, 12843,   382,   791,  3878, 58629,   323,\n",
      "         1207,   527, 24716,   304,   279,  2326,   323,   539, 90547,   311,\n",
      "          904,  3738,   961,    11,  3582,  1690,   315,   279, 44589,  3878,\n",
      "          527, 93858,   304,   279, 87244,  3723,  4273,   382, 13730,   323,\n",
      "         1880, 99174,   198,   791], device='cuda:0')\n",
      "Epoch 0, Batch 13, Loss: 11.557793617248535\n",
      "Batch 14, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-0.0057,  0.3728,  0.2046,  ..., -0.2411,  0.1470,  0.0451],\n",
      "         [-0.3992, -0.2595,  0.2413,  ...,  0.3394, -0.0877, -0.1071],\n",
      "         [-0.1287,  0.0912,  0.0491,  ..., -0.0263, -0.0924,  0.0387],\n",
      "         ...,\n",
      "         [-0.1098,  0.1737, -0.2030,  ..., -0.0521,  0.0762,  0.1864],\n",
      "         [ 0.1819,  0.0736, -0.1796,  ...,  0.2625,  0.0562,  0.4248],\n",
      "         [-0.7095,  0.0542,  0.3906,  ..., -0.0812, -0.4397, -0.5220]],\n",
      "\n",
      "        [[-0.0188,  0.3574,  0.2261,  ..., -0.1667,  0.1697,  0.0612],\n",
      "         [-0.0024,  0.2590,  0.1437,  ..., -0.0184,  0.1697,  0.1090],\n",
      "         [-0.0102, -0.2128,  0.0631,  ..., -0.0335,  0.1225,  0.0459],\n",
      "         ...,\n",
      "         [-0.0325,  0.3176,  0.1409,  ...,  0.3040, -0.1917,  0.4766],\n",
      "         [-0.0415, -0.0412, -0.0112,  ...,  0.0174,  0.4099,  0.1256],\n",
      "         [-0.2272, -0.1897,  0.1658,  ..., -0.2874,  0.0584,  0.1757]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[82389, 32817,  4910,   374,   264, 14458,   304, 11940,  6406,    11,\n",
      "         19174,    11,  3723,  4273,    13,  3700,   279,   220,  2366,    15,\n",
      "         44702,    11,   279,  7187,   574,   220,    20,    11,  1041,   382,\n",
      "          9688,  5814,   198, 82389, 32817,  4910,   374,  7559,   520,   220,\n",
      "           320,  2983,    13, 11227, 21876,    15,    11,   482,  2421,    13,\n",
      "          8953, 24130,    21,   570,   578, 14458,   374,  1101, 31183,   389,\n",
      "           279, 63263,   315, 11940, 32817,  4910,    11,   902,   574,  8767,\n",
      "          2663,  7904, 11940,    11,  7559,   520,  6905, 11439,   311,   279,\n",
      "           220,   679,    15, 44702,    11, 11940, 32817,  4910,   706,   264,\n",
      "          2860,  3158,   315,  1174,   315,   902,   220,   320,   269,   220,\n",
      "          2721,    13,  2437, 11587,   374,  4363,   323,   220,   320,   269,\n",
      "           220,    19,    13,  3264, 11587,   374,  3090,   382, 33103, 45245,\n",
      "           271,  2366,    15, 44702,   271,  1049,    15],\n",
      "        [26287,  6798,   374,   264,  6424,   304,  9305, 24125,  6406,    11,\n",
      "          1561, 31997,    11,  3723,  4273,    13,   578,  7187,   574,   220,\n",
      "            19,    11, 23525,   520,   279,   220,  2366,    15, 44702,   382,\n",
      "         13730,  4815,  5451, 23183,   304,   220, 10967,    18,    11,  4892,\n",
      "          6798,   574, 32762,   389,  7552,   220,    21,    11,   220, 11242,\n",
      "            18,   555, 37683, 19582,  3842, 54859, 20069,    11,   994,   264,\n",
      "          3544, 42929,   315,  4363,  2663,   330, 26287, 35848,     1,   574,\n",
      "         19180,   505, 67659,    13, 33916,   220,  5245,    15,    11,   279,\n",
      "         87670,   311, 64193, 12268, 65546,   574,  5918,    11,   323,   279,\n",
      "          6424,  6137,   311, 29761,    13, 86915, 91235,    82, 14252,   660,\n",
      "           274,  4995,   323,  6566, 22961,    13,  2468,   832,   892,    11,\n",
      "          1070,  1051,  1063, 30335,  5602,    76,  3385,   304,   279,  6424,\n",
      "            11,  4330,   315,   902,  1051, 12860,   555]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0057,  0.3728,  0.2046,  ..., -0.2411,  0.1470,  0.0451],\n",
      "        [-0.3992, -0.2595,  0.2413,  ...,  0.3394, -0.0877, -0.1071],\n",
      "        [-0.1287,  0.0912,  0.0491,  ..., -0.0263, -0.0924,  0.0387],\n",
      "        ...,\n",
      "        [-0.0325,  0.3176,  0.1409,  ...,  0.3040, -0.1917,  0.4766],\n",
      "        [-0.0415, -0.0412, -0.0112,  ...,  0.0174,  0.4099,  0.1256],\n",
      "        [-0.2272, -0.1897,  0.1658,  ..., -0.2874,  0.0584,  0.1757]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([82389, 32817,  4910,   374,   264, 14458,   304, 11940,  6406,    11,\n",
      "        19174,    11,  3723,  4273,    13,  3700,   279,   220,  2366,    15,\n",
      "        44702,    11,   279,  7187,   574,   220,    20,    11,  1041,   382,\n",
      "         9688,  5814,   198, 82389, 32817,  4910,   374,  7559,   520,   220,\n",
      "          320,  2983,    13, 11227, 21876,    15,    11,   482,  2421,    13,\n",
      "         8953, 24130,    21,   570,   578, 14458,   374,  1101, 31183,   389,\n",
      "          279, 63263,   315, 11940, 32817,  4910,    11,   902,   574,  8767,\n",
      "         2663,  7904, 11940,    11,  7559,   520,  6905, 11439,   311,   279,\n",
      "          220,   679,    15, 44702,    11, 11940, 32817,  4910,   706,   264,\n",
      "         2860,  3158,   315,  1174,   315,   902,   220,   320,   269,   220,\n",
      "         2721,    13,  2437, 11587,   374,  4363,   323,   220,   320,   269,\n",
      "          220,    19,    13,  3264, 11587,   374,  3090,   382, 33103, 45245,\n",
      "          271,  2366,    15, 44702,   271,  1049,    15, 26287,  6798,   374,\n",
      "          264,  6424,   304,  9305, 24125,  6406,    11,  1561, 31997,    11,\n",
      "         3723,  4273,    13,   578,  7187,   574,   220,    19,    11, 23525,\n",
      "          520,   279,   220,  2366,    15, 44702,   382, 13730,  4815,  5451,\n",
      "        23183,   304,   220, 10967,    18,    11,  4892,  6798,   574, 32762,\n",
      "          389,  7552,   220,    21,    11,   220, 11242,    18,   555, 37683,\n",
      "        19582,  3842, 54859, 20069,    11,   994,   264,  3544, 42929,   315,\n",
      "         4363,  2663,   330, 26287, 35848,     1,   574, 19180,   505, 67659,\n",
      "           13, 33916,   220,  5245,    15,    11,   279, 87670,   311, 64193,\n",
      "        12268, 65546,   574,  5918,    11,   323,   279,  6424,  6137,   311,\n",
      "        29761,    13, 86915, 91235,    82, 14252,   660,   274,  4995,   323,\n",
      "         6566, 22961,    13,  2468,   832,   892,    11,  1070,  1051,  1063,\n",
      "        30335,  5602,    76,  3385,   304,   279,  6424,    11,  4330,   315,\n",
      "          902,  1051, 12860,   555], device='cuda:0')\n",
      "Epoch 0, Batch 14, Loss: 11.530511856079102\n",
      "Batch 15, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-0.0101,  0.3516,  0.2495,  ..., -0.1897,  0.1823,  0.0468],\n",
      "         [-0.0444,  0.0333,  0.0775,  ...,  0.0976,  0.0862, -0.4485],\n",
      "         [ 0.2725,  0.2527,  0.4712,  ..., -0.2786, -0.0161, -0.0105],\n",
      "         ...,\n",
      "         [-0.2428,  0.0052, -0.1078,  ...,  0.1566,  0.0497,  0.1536],\n",
      "         [-0.3135,  0.0942,  0.3230,  ..., -0.1788,  0.0392,  0.3054],\n",
      "         [-0.3499, -0.1097, -0.0296,  ...,  0.0673, -0.1807,  0.2979]],\n",
      "\n",
      "        [[ 0.0036,  0.3342,  0.2352,  ..., -0.2083,  0.1879,  0.0258],\n",
      "         [ 0.1066,  0.1702, -0.2366,  ...,  0.0008, -0.0664,  0.1130],\n",
      "         [ 0.1244, -0.1703, -0.1395,  ...,  0.4089, -0.0383,  0.3232],\n",
      "         ...,\n",
      "         [-0.2346,  0.0692, -0.0531,  ..., -0.2421, -0.1584,  0.2686],\n",
      "         [ 0.1613, -0.0507,  0.1103,  ..., -0.1594, -0.0663,  0.4436],\n",
      "         [-0.0286, -0.2327, -0.0798,  ...,  0.1086, -0.1486,  0.1466]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[  791,  8752,   315, 48847,   374,   459, 24084,    11,  9709,  8752,\n",
      "         32971,   555,   264,  1579,  2237,   315,  7362,  6696,   323,   459,\n",
      "          8582,  6278,  8070,  8752,   439, 21771,   555,   279,  4435,  8715,\n",
      "            13, 48847,   706,   279, 36498,  7962, 45707,  7928,  8752,   304,\n",
      "           279,  1917,   555,  2860, 30830,   323,  5131, 11704,   264,  1579,\n",
      "          3823,  4500,  1963,    13,   578,  3224,   574,   832,   315,   279,\n",
      "          1917,   596, 26731, 56657, 37671,   304,   220,   679,    17,    11,\n",
      "           449,   264, 30830,  6650,  4478,   315,   220,    21,    13,    18,\n",
      "         14697,   578,  8752,   574,  3685,   311,  5376,   220,    24,    13,\n",
      "            18,     4,   304,   220,  2366,    16,    11,   304,   264, 42632,\n",
      "           505,   279, 20562,    12,   777, 28522,   304, 48847,    13, 48847,\n",
      "           706,  8667,   264,  1396,   315,  1949,  6696, 20038,   449,  1202,\n",
      "          1925,  6696,  8717,    13,  5734,  6244,   279],\n",
      "        [ 1163, 60539, 25036,   374,   264,  3363,   304, 89984,   323, 40361,\n",
      "         31276,   304,   279,   549,   815,    13,  1614,   315, 32790,    13,\n",
      "           578,  7187,   574,   220,    19,    11, 23403,   520,   279,   220,\n",
      "           679,    15, 44702,    11,   449,   264,   220,  7187,   315,   220,\n",
      "            19,    11, 19423,   304,   220,  2366,    15,   320,    34, 13940,\n",
      "          3677,  9688,  5814,   198,  1163, 60539, 25036,   374,  7559,   520,\n",
      "           220,   320,  1927,    13, 17313, 17212,    11,   482,  5925,    13,\n",
      "         22468, 17014,  3677, 11439,   311,   279,  3723,  4273, 46627, 22555,\n",
      "            11,   279,  3363,   706,   264,  2860,  3158,   315,  1174,   315,\n",
      "           902,   220,   374,  4363,   323,   220,   320,    19,    13,   777,\n",
      "         11587,   374,  3090,   382,   791,  3363, 13693,  2997,  8254, 44236,\n",
      "           323,  1403,  3678, 20718,    13,   578,  7928,   374, 11940, 27789,\n",
      "         23414,   449,   927,  8254,  8931,   315, 99164]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0101,  0.3516,  0.2495,  ..., -0.1897,  0.1823,  0.0468],\n",
      "        [-0.0444,  0.0333,  0.0775,  ...,  0.0976,  0.0862, -0.4485],\n",
      "        [ 0.2725,  0.2527,  0.4712,  ..., -0.2786, -0.0161, -0.0105],\n",
      "        ...,\n",
      "        [-0.2346,  0.0692, -0.0531,  ..., -0.2421, -0.1584,  0.2686],\n",
      "        [ 0.1613, -0.0507,  0.1103,  ..., -0.1594, -0.0663,  0.4436],\n",
      "        [-0.0286, -0.2327, -0.0798,  ...,  0.1086, -0.1486,  0.1466]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([  791,  8752,   315, 48847,   374,   459, 24084,    11,  9709,  8752,\n",
      "        32971,   555,   264,  1579,  2237,   315,  7362,  6696,   323,   459,\n",
      "         8582,  6278,  8070,  8752,   439, 21771,   555,   279,  4435,  8715,\n",
      "           13, 48847,   706,   279, 36498,  7962, 45707,  7928,  8752,   304,\n",
      "          279,  1917,   555,  2860, 30830,   323,  5131, 11704,   264,  1579,\n",
      "         3823,  4500,  1963,    13,   578,  3224,   574,   832,   315,   279,\n",
      "         1917,   596, 26731, 56657, 37671,   304,   220,   679,    17,    11,\n",
      "          449,   264, 30830,  6650,  4478,   315,   220,    21,    13,    18,\n",
      "        14697,   578,  8752,   574,  3685,   311,  5376,   220,    24,    13,\n",
      "           18,     4,   304,   220,  2366,    16,    11,   304,   264, 42632,\n",
      "          505,   279, 20562,    12,   777, 28522,   304, 48847,    13, 48847,\n",
      "          706,  8667,   264,  1396,   315,  1949,  6696, 20038,   449,  1202,\n",
      "         1925,  6696,  8717,    13,  5734,  6244,   279,  1163, 60539, 25036,\n",
      "          374,   264,  3363,   304, 89984,   323, 40361, 31276,   304,   279,\n",
      "          549,   815,    13,  1614,   315, 32790,    13,   578,  7187,   574,\n",
      "          220,    19,    11, 23403,   520,   279,   220,   679,    15, 44702,\n",
      "           11,   449,   264,   220,  7187,   315,   220,    19,    11, 19423,\n",
      "          304,   220,  2366,    15,   320,    34, 13940,  3677,  9688,  5814,\n",
      "          198,  1163, 60539, 25036,   374,  7559,   520,   220,   320,  1927,\n",
      "           13, 17313, 17212,    11,   482,  5925,    13, 22468, 17014,  3677,\n",
      "        11439,   311,   279,  3723,  4273, 46627, 22555,    11,   279,  3363,\n",
      "          706,   264,  2860,  3158,   315,  1174,   315,   902,   220,   374,\n",
      "         4363,   323,   220,   320,    19,    13,   777, 11587,   374,  3090,\n",
      "          382,   791,  3363, 13693,  2997,  8254, 44236,   323,  1403,  3678,\n",
      "        20718,    13,   578,  7928,   374, 11940, 27789, 23414,   449,   927,\n",
      "         8254,  8931,   315, 99164], device='cuda:0')\n",
      "Epoch 0, Batch 15, Loss: 11.56812858581543\n",
      "Batch 16, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n",
      "shift_logits: tensor([[[-0.0077,  0.3535,  0.2305,  ..., -0.1885,  0.1179,  0.0520],\n",
      "         [-0.3596, -0.0712,  0.1149,  ..., -0.2443, -0.0641,  0.4089],\n",
      "         [ 0.0961,  0.0420,  0.4072,  ..., -0.3147, -0.1611, -0.0200],\n",
      "         ...,\n",
      "         [-0.0186, -0.0554,  0.0905,  ..., -0.1710, -0.0545, -0.0253],\n",
      "         [ 0.2974,  0.1490,  0.1360,  ..., -0.1477, -0.4172,  0.1987],\n",
      "         [ 0.1952,  0.1493, -0.0154,  ...,  0.3816, -0.0603, -0.3298]],\n",
      "\n",
      "        [[-0.0341,  0.3391,  0.2283,  ..., -0.2059,  0.1924,  0.0544],\n",
      "         [-0.3474,  0.2969,  0.4568,  ...,  0.2042, -0.0112, -0.0812],\n",
      "         [-0.1989,  0.1290, -0.1113,  ...,  0.0792, -0.4851,  0.2559],\n",
      "         ...,\n",
      "         [ 0.2708,  0.0464,  0.2450,  ..., -0.3721, -0.1148,  0.0165],\n",
      "         [ 0.2460, -0.0260,  0.1405,  ..., -0.2954,  0.0370,  0.1053],\n",
      "         [-0.0561, -0.0376,  0.3572,  ..., -0.0903, -0.0744, -0.1630]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<CloneBackward0>)\n",
      "shift_labels: tensor([[  644, 18341, 59492,    11,  2009, 95514,  1820,    64, 31475,  7026,\n",
      "          7170,  1101,  2663,  2009, 95514,   339,  4748, 39204,   574,   832,\n",
      "           315,   279, 13878,  1234,   902,   459, 14154,  9581, 52190,   574,\n",
      "         15324,    11,   304,   420,  1162,   439,   264, 24411, 99401,   382,\n",
      "          5159,   339,  2508,   720,   644,   279,   810, 11537, 11678,    11,\n",
      "           763,    78,    11,   279, 10003,   315, 33160, 38827,    11, 13219,\n",
      "           315,   328,  3981,   273,    11,   323, 29006,   315, 20277, 29189,\n",
      "            11,  6244,   264, 52190,   220,  1306, 83657, 23980,  1077, 35118,\n",
      "           439,   264, 25060,   369, 30598,   369,   279, 46397, 65157,  1065,\n",
      "           355,    13,  3005,   514,  2756,  1139,   279,  9581,   449,  1077,\n",
      "          4538, 11220,   292,   531,   288,   304,  1077, 11977,    11,   323,\n",
      "           704,   315, 58043,    11,   279,   473, 16046,   288, 50697,    11,\n",
      "           279, 15136,  1122, 29913,  6656,  1124,  2225],\n",
      "        [ 1542,   278, 18063, 12225,   817, 13562, 12225,   372,   579, 63140,\n",
      "          8083, 33007,   320, 16381,   220,   777,  7552,   220,  5162,    18,\n",
      "           705,  3967,  1647,  7987,  7162,   439, 53625,    11,   374,   264,\n",
      "          8013, 39844,    11, 23597,    11, 85757,    11,   323,  3335, 17276,\n",
      "            13,  1283,   706,  6216,   927,   220,   508,  3610,  7576, 15603,\n",
      "            13,  4314,  2997,  4295, 11936,   330,    34, 12350,     1,   323,\n",
      "           330,    42, 15610,   498,   279, 15629,   315,   902,  4024,   311,\n",
      "          1396,   832,   304,   279,  6560,    11,   323,   813,  1455, 28284,\n",
      "          5609,    11,   330,    42,  1056,   505,   264, 16344,   498,   902,\n",
      "           574,  6004,   304,   220,  2550,    19,    13,  4815,  1542,   278,\n",
      "           706,  2834,  5361, 23146,  6957,   813,  7076,    11,  2737,  2380,\n",
      "          5567, 23488,    26,   568,  2834,  7252,  8013, 19960,   304,   220,\n",
      "          2550,    17,    13,  1283,   706,  1101,  2834]], device='cuda:0')\n",
      "masked_logits.shape: torch.Size([254, 100512]), masked_labels.shape: torch.Size([254])\n",
      "masked_logits: tensor([[-0.0077,  0.3535,  0.2305,  ..., -0.1885,  0.1179,  0.0520],\n",
      "        [-0.3596, -0.0712,  0.1149,  ..., -0.2443, -0.0641,  0.4089],\n",
      "        [ 0.0961,  0.0420,  0.4072,  ..., -0.3147, -0.1611, -0.0200],\n",
      "        ...,\n",
      "        [ 0.2708,  0.0464,  0.2450,  ..., -0.3721, -0.1148,  0.0165],\n",
      "        [ 0.2460, -0.0260,  0.1405,  ..., -0.2954,  0.0370,  0.1053],\n",
      "        [-0.0561, -0.0376,  0.3572,  ..., -0.0903, -0.0744, -0.1630]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "masked_labels: tensor([  644, 18341, 59492,    11,  2009, 95514,  1820,    64, 31475,  7026,\n",
      "         7170,  1101,  2663,  2009, 95514,   339,  4748, 39204,   574,   832,\n",
      "          315,   279, 13878,  1234,   902,   459, 14154,  9581, 52190,   574,\n",
      "        15324,    11,   304,   420,  1162,   439,   264, 24411, 99401,   382,\n",
      "         5159,   339,  2508,   720,   644,   279,   810, 11537, 11678,    11,\n",
      "          763,    78,    11,   279, 10003,   315, 33160, 38827,    11, 13219,\n",
      "          315,   328,  3981,   273,    11,   323, 29006,   315, 20277, 29189,\n",
      "           11,  6244,   264, 52190,   220,  1306, 83657, 23980,  1077, 35118,\n",
      "          439,   264, 25060,   369, 30598,   369,   279, 46397, 65157,  1065,\n",
      "          355,    13,  3005,   514,  2756,  1139,   279,  9581,   449,  1077,\n",
      "         4538, 11220,   292,   531,   288,   304,  1077, 11977,    11,   323,\n",
      "          704,   315, 58043,    11,   279,   473, 16046,   288, 50697,    11,\n",
      "          279, 15136,  1122, 29913,  6656,  1124,  2225,  1542,   278, 18063,\n",
      "        12225,   817, 13562, 12225,   372,   579, 63140,  8083, 33007,   320,\n",
      "        16381,   220,   777,  7552,   220,  5162,    18,   705,  3967,  1647,\n",
      "         7987,  7162,   439, 53625,    11,   374,   264,  8013, 39844,    11,\n",
      "        23597,    11, 85757,    11,   323,  3335, 17276,    13,  1283,   706,\n",
      "         6216,   927,   220,   508,  3610,  7576, 15603,    13,  4314,  2997,\n",
      "         4295, 11936,   330,    34, 12350,     1,   323,   330,    42, 15610,\n",
      "          498,   279, 15629,   315,   902,  4024,   311,  1396,   832,   304,\n",
      "          279,  6560,    11,   323,   813,  1455, 28284,  5609,    11,   330,\n",
      "           42,  1056,   505,   264, 16344,   498,   902,   574,  6004,   304,\n",
      "          220,  2550,    19,    13,  4815,  1542,   278,   706,  2834,  5361,\n",
      "        23146,  6957,   813,  7076,    11,  2737,  2380,  5567, 23488,    26,\n",
      "          568,  2834,  7252,  8013, 19960,   304,   220,  2550,    17,    13,\n",
      "         1283,   706,  1101,  2834], device='cuda:0')\n",
      "Epoch 0, Batch 16, Loss: 11.53650951385498\n",
      "Batch 17, shift_logits.shape: torch.Size([2, 127, 100512]), shift_labels.shape: torch.Size([2, 127])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [70,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1290: indexSelectLargeIndex: block: [118,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 120\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Debug: Print shapes and values\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, shift_logits.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshift_logits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, shift_labels.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshift_labels\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshift_logits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshift_logits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshift_labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshift_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Mask out padding from the loss calculation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:966\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[0;32m--> 966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:461\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    458\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    459\u001b[0m     )\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_tensor_str\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor_str.py:677\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    676\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _str_intern(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor_str.py:597\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    596\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 597\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m, indent)\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    600\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor_str.py:349\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 349\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m _Formatter(get_summarized_data(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor_str.py:137\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(\n\u001b[1;32m    138\u001b[0m         tensor_view, torch\u001b[38;5;241m.\u001b[39misfinite(tensor_view) \u001b[38;5;241m&\u001b[39m tensor_view\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from datasets import load_dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tokenizer import Tokenizer  # Assuming your tokenizer script is named tokenizer.py\n",
    "\n",
    "# Load the dataset\n",
    "NUM_PROC = 24\n",
    "BATCH_SIZE = 2  # Reduced batch size to handle memory issues\n",
    "MAX_SEQ_LEN = 128  # Reduced sequence length to handle memory issues\n",
    "\n",
    "dataset = load_dataset(\"wikipedia\", language=\"en\", date=\"20240401\", split='train[:1%]', num_proc=NUM_PROC, trust_remote_code=True)\n",
    "tokenizer_path = 'cl100k_base.tiktoken'\n",
    "tokenizer = Tokenizer(tokenizer_path)\n",
    "\n",
    "# Tokenization and data preparation\n",
    "def tokenize_function(examples):\n",
    "    input_ids = [tokenizer.encode(text, bos=True, eos=True) for text in examples['text']]\n",
    "    return {'input_ids': input_ids}\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=NUM_PROC)\n",
    "tokenized_datasets.set_format('torch', columns=['input_ids'])\n",
    "\n",
    "# Data loader setup\n",
    "def collate_batch(batch):\n",
    "    input_ids_list = [item['input_ids'].clone().detach().to(torch.long) for item in batch]\n",
    "    padded_input_ids = [\n",
    "        ids[:MAX_SEQ_LEN] if len(ids) > MAX_SEQ_LEN else F.pad(ids, (0, MAX_SEQ_LEN - len(ids)), value=tokenizer.pad_id)\n",
    "        for ids in input_ids_list\n",
    "    ]\n",
    "    return {'input_ids': pad_sequence(padded_input_ids, batch_first=True, padding_value=tokenizer.pad_id)}\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_datasets, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "# Model definition\n",
    "class ModelArgs:\n",
    "    def __init__(self, vocab_size, dim, n_layers, n_heads, ffn_dim_multiplier):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dim = dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.ffn_dim_multiplier = ffn_dim_multiplier\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(args.vocab_size, args.dim)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=args.dim, nhead=args.n_heads, dim_feedforward=int(args.dim * args.ffn_dim_multiplier))\n",
    "            for _ in range(args.n_layers)\n",
    "        ])\n",
    "        self.linear = nn.Linear(args.dim, args.vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Model arguments\n",
    "model_args = ModelArgs(\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    dim=128,  # Reduced dimensions for memory efficiency\n",
    "    n_layers=2,  # Reduced layers\n",
    "    n_heads=4,  # Reduced heads\n",
    "    ffn_dim_multiplier=2  # Reduced feed-forward size\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = Transformer(model_args)\n",
    "\n",
    "# Initialize weights\n",
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Embedding)):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.normal_(m.weight, mean=1.0, std=0.02)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Setup optimizer and scaler\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # Reduced learning rate\n",
    "scaler = GradScaler()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# Gradient clipping function\n",
    "def clip_gradients(model, max_norm=1.0):\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "# Enable CUDA debugging\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "for epoch in range(1):  # Example: one epoch\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = input_ids.clone()  # Assuming labels are the shifted input_ids\n",
    "\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        with autocast():\n",
    "            outputs = model(input_ids)\n",
    "\n",
    "            # Clamp logits to avoid NaNs\n",
    "            outputs = torch.clamp(outputs, min=-1e9, max=1e9)\n",
    "\n",
    "            shift_logits = outputs[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "            # Debug: Print shapes and some statistics\n",
    "            print(f\"Batch {i}, shift_logits.shape: {shift_logits.shape}, shift_labels.shape: {shift_labels.shape}\")\n",
    "            print(f\"shift_logits stats: min={shift_logits.min()}, max={shift_logits.max()}, mean={shift_logits.mean()}\")\n",
    "            print(f\"shift_labels stats: min={shift_labels.min()}, max={shift_labels.max()}, mean={shift_labels.mean()}\")\n",
    "\n",
    "            # Mask out padding from the loss calculation\n",
    "            mask = shift_labels != tokenizer.pad_id\n",
    "            masked_logits = shift_logits[mask]\n",
    "            masked_labels = shift_labels[mask]\n",
    "\n",
    "            # Debug: Check masked logits and labels\n",
    "            print(f\"masked_logits.shape: {masked_logits.shape}, masked_labels.shape: {masked_labels.shape}\")\n",
    "            print(f\"masked_logits stats: min={masked_logits.min()}, max={masked_logits.max()}, mean={masked_logits.mean()}\")\n",
    "            print(f\"masked_labels stats: min={masked_labels.min()}, max={masked_labels.max()}, mean={masked_labels.mean()}\")\n",
    "\n",
    "            if masked_logits.numel() > 0:\n",
    "                if torch.isnan(masked_logits).any():\n",
    "                    print(f\"NaN detected in logits at Batch {i}\")\n",
    "                    continue\n",
    "\n",
    "                if torch.isnan(masked_labels).any():\n",
    "                    print(f\"NaN detected in labels at Batch {i}\")\n",
    "                    continue\n",
    "\n",
    "                loss = F.cross_entropy(masked_logits.view(-1, masked_logits.size(-1)), masked_labels.view(-1))\n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"NaN detected in loss at Batch {i}\")\n",
    "                    continue\n",
    "                \n",
    "                # Scale loss and perform backward\n",
    "                scaler.scale(loss).backward()\n",
    "                clip_gradients(model)  # Gradient clipping\n",
    "            else:\n",
    "                # Skip the backward pass if there's no valid data\n",
    "                print(\"Skipping backward as no valid data is present in this batch.\")\n",
    "                continue\n",
    "\n",
    "        # Perform optimization step and clear gradients at defined accumulation steps\n",
    "        if (i + 1) % BATCH_SIZE == 0 or i == len(train_dataloader) - 1:  # ensure last batch is used\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Batch {i}, Loss: {loss.item() if 'loss' in locals() else 'No Loss Computed'}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'llm_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
